{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1P1TkZJNxcgr"
      },
      "source": [
        "# DPK Example: Detect Hate Abuse and Profanity (HAP) speech\n",
        "\n",
        " [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sujee/data-prep-kit-examples/blob/main/data-prep-kit/hap_1.ipynb)\n",
        "\n",
        " This notebook will illustrate how we can use Data Prep Kit's  [HAP detector](https://github.com/data-prep-kit/data-prep-kit/tree/dev/transforms/universal/hap) to tag HAP speech in documents.\n",
        "\n",
        " References and credits:\n",
        "\n",
        " - https://github.com/data-prep-kit/data-prep-kit/tree/dev/transforms/universal/hap\n",
        " - https://github.com/data-prep-kit/data-prep-kit/blob/dev/transforms/universal/hap/hap_python.ipynb\n",
        " - https://github.com/proz92/RAG-with-watsonx-HAP-Guardrails\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9JSyFA9xcgu"
      },
      "source": [
        "## Step-1: Figure out Runtime Environment\n",
        "\n",
        "### 1.1 - Determine runtime\n",
        "\n",
        "Determine if we are running on Google colab or local python environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2-3VsdJNxcgv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NOT in Colab\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "   print(\"Running in Colab\")\n",
        "   RUNNING_IN_COLAB = True\n",
        "else:\n",
        "   print(\"NOT in Colab\")\n",
        "   RUNNING_IN_COLAB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAzj7p9Gxcgx"
      },
      "source": [
        "### 1.2 - Install dependencies if running on Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_eGv5q6Excgz"
      },
      "outputs": [],
      "source": [
        "## Download any code files we may need\n",
        "\n",
        "if RUNNING_IN_COLAB:\n",
        "    !wget -O 'file_utils.py'   'https://raw.githubusercontent.com/sujee/data-prep-kit-examples/main/data-prep-kit/file_utils.py'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-1y00Npcxcgx"
      },
      "outputs": [],
      "source": [
        "# %%capture\n",
        "# %%time\n",
        "\n",
        "import os\n",
        "\n",
        "if RUNNING_IN_COLAB:\n",
        "  ## setup a sandbox env to avoid conflicts with colab libraries\n",
        "  !pip install -q condacolab\n",
        "  import condacolab\n",
        "  condacolab.install()\n",
        "\n",
        "  !conda create -n my_env python=3.11 -y\n",
        "  !conda activate my_env\n",
        "  !pip install  --default-timeout=100  \\\n",
        "        'data-prep-toolkit-transforms[hap, pdf2parquet]'==1.1.0 \\\n",
        "        humanfriendly\n",
        "  ## terminate the current kernel, so we restart the runtime\n",
        "  os.kill(os.getpid(), 9)\n",
        "  ## restart the session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qF_a2lnnxcgy"
      },
      "source": [
        "### 1.3 - Restart Runtime\n",
        "\n",
        "After installing dependencies, you may want to <font color=\"red\">restart runtime</font>, so libraries will be loaded\n",
        "\n",
        "You do this by going to **`Runtime --> Restart Session`**\n",
        "\n",
        "Then you can continue to the next step (no need to re-run the notebook)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4IpxhpAxcgy"
      },
      "source": [
        "## Step-2: Configuration  & Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR23Gplqxcgy"
      },
      "source": [
        "### 2.1 - Basic Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w2ppGvvxcgz",
        "outputId": "efa243ce-164b-44d5-afc8-8b6829e3b7b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NOT in Colab\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "   print(\"Running in Colab\")\n",
        "   RUNNING_IN_COLAB = True\n",
        "else:\n",
        "   print(\"NOT in Colab\")\n",
        "   RUNNING_IN_COLAB = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PfIa1CRxcg0"
      },
      "source": [
        "### 2.2 - Setup input/outpur directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cnD-i_fAxcg0"
      },
      "outputs": [],
      "source": [
        "## setup path to utils folder\n",
        "import sys\n",
        "sys.path.append('../utils')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0LMI8DEHxcg0"
      },
      "outputs": [],
      "source": [
        "# If connection to https://huggingface.co/ failed, uncomment the following path\n",
        "import os\n",
        "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPW05bBlxcg1",
        "outputId": "d36e5660-9330-473e-c1ce-badbce9756e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Cleared output directory\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "import shutil\n",
        "\n",
        "if RUNNING_IN_COLAB:\n",
        "    input_dir = \"input/\"\n",
        "    shutil.os.makedirs(input_dir, exist_ok=True)\n",
        "else:\n",
        "    input_dir = \"../data/hap/\"\n",
        "\n",
        "output_dir = \"output\"\n",
        "output_pdf2pq_dir = os.path.join (output_dir, '01_pdf2pq_out')\n",
        "output_hap_dir = os.path.join (output_dir, '02_hap_out')\n",
        "output_md_dir = os.path.join (output_dir, \"03_md\")\n",
        "\n",
        "\n",
        "## clear output folder\n",
        "shutil.rmtree(output_dir, ignore_errors=True)\n",
        "shutil.os.makedirs(output_dir, exist_ok=True)\n",
        "shutil.os.makedirs(output_md_dir, exist_ok=True)\n",
        "print (\"✅ Cleared output directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YId4EeKxcg1"
      },
      "source": [
        "## Step-3: Inspect the Data\n",
        "\n",
        "Sample data files are [here](https://github.com/sujee/data-prep-kit-examples/tree/main/data/hap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBoclRj-xcg1"
      },
      "source": [
        "### 3.1 -Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Vqt87h8xcg2",
        "outputId": "16d0cf00-e85f-4f59-e25a-03ac544ddb25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input :  ../data/hap/\n"
          ]
        }
      ],
      "source": [
        "from file_utils import download_file\n",
        "\n",
        "if RUNNING_IN_COLAB:\n",
        "    download_file ('https://raw.githubusercontent.com/sujee/data-prep-kit-examples/main/data/hap/earth.pdf', os.path.join(input_dir, 'earth.pdf'))\n",
        "    download_file ('https://raw.githubusercontent.com/sujee/data-prep-kit-examples/main/data/hap/hap1.pdf', os.path.join(input_dir, 'hap1.pdf'))\n",
        "    download_file ('https://raw.githubusercontent.com/sujee/data-prep-kit-examples/main/data/hap/hap2.pdf', os.path.join(input_dir, 'hap2.pdf'))\n",
        "    download_file ('https://raw.githubusercontent.com/sujee/data-prep-kit-examples/main/data/hap/hap3.pdf', os.path.join(input_dir, 'hap3.pdf'))\n",
        "    download_file ('https://raw.githubusercontent.com/sujee/data-prep-kit-examples/main/data/hap/hap4.pdf', os.path.join(input_dir, 'hap4.pdf'))\n",
        "else:\n",
        "    print ('input : ', input_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHAE9V51xcg2"
      },
      "source": [
        "## Step-4: Extract Data from PDF (pdf2parquet)\n",
        "\n",
        "This step we will read PDF files and extract the text data.\n",
        "\n",
        "[Pdf2Parquet documentation](https://github.com/IBM/data-prep-kit/blob/dev/transforms/language/pdf2parquet/README.md)\n",
        "\n",
        "We use the [Docling package](https://github.com/DS4SD/docling)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 - Execute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtaYiY71xcg2",
        "outputId": "6ddce45b-5e91-4c5f-ec4f-b312b5cca993"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🏃🏼 Processing input='../data/hap/' --> output='output/01_pdf2pq_out'\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12:05:39 INFO - pdf2parquet parameters are : {'batch_size': -1, 'artifacts_path': None, 'contents_type': <pdf2parquet_contents_types.MARKDOWN: 'text/markdown'>, 'do_table_structure': True, 'do_ocr': True, 'ocr_engine': <pdf2parquet_ocr_engine.EASYOCR: 'easyocr'>, 'bitmap_area_threshold': 0.05, 'pdf_backend': <pdf2parquet_pdf_backend.DLPARSE_V2: 'dlparse_v2'>, 'double_precision': 8}\n",
            "12:05:39 INFO - pipeline id pipeline_id\n",
            "12:05:39 INFO - code location None\n",
            "12:05:39 INFO - data factory data_ is using local data access: input_folder - ../data/hap/ output_folder - output/01_pdf2pq_out\n",
            "12:05:39 INFO - data factory data_ max_files -1, n_sample -1\n",
            "12:05:39 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.pdf'], files to checkpoint ['.parquet']\n",
            "12:05:39 INFO - orchestrator pdf2parquet started at 2025-03-26 12:05:39\n",
            "12:05:39 INFO - Number of files is 5, source profile {'max_file_size': 0.055823326110839844, 'min_file_size': 0.04489898681640625, 'total_file_size': 0.24595928192138672}\n",
            "12:05:39 INFO - Initializing models\n",
            "Could not load the custom kernel for multi-scale deformable attention: Error building extension 'MultiScaleDeformableAttention': [1/3] /usr/bin/nvcc --generate-dependencies-with-compile --dependency-output ms_deform_attn_cuda.cuda.o.d -ccbin /home/sujee/apps/anaconda3/bin/x86_64-conda-linux-gnu-cc -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/transformers/kernels/deformable_detr -isystem /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/torch/include -isystem /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/torch/include/TH -isystem /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/torch/include/THC -isystem /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -std=c++17 -c /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu -o ms_deform_attn_cuda.cuda.o \n",
            "\u001b[31mFAILED: \u001b[0mms_deform_attn_cuda.cuda.o \n",
            "/usr/bin/nvcc --generate-dependencies-with-compile --dependency-output ms_deform_attn_cuda.cuda.o.d -ccbin /home/sujee/apps/anaconda3/bin/x86_64-conda-linux-gnu-cc -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/transformers/kernels/deformable_detr -isystem /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/torch/include -isystem /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/torch/include/TH -isystem /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/torch/include/THC -isystem /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -std=c++17 -c /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu -o ms_deform_attn_cuda.cuda.o \n",
            "/bin/sh: 1: /usr/bin/nvcc: not found\n",
            "[2/3] /home/sujee/apps/anaconda3/bin/x86_64-conda-linux-gnu-c++ -MMD -MF ms_deform_attn_cpu.o.d -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/transformers/kernels/deformable_detr -isystem /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/torch/include -isystem /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/torch/include/TH -isystem /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/torch/include/THC -isystem /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -DWITH_CUDA=1 -c /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/transformers/kernels/deformable_detr/cpu/ms_deform_attn_cpu.cpp -o ms_deform_attn_cpu.o \n",
            "\u001b[31mFAILED: \u001b[0mms_deform_attn_cpu.o \n",
            "/home/sujee/apps/anaconda3/bin/x86_64-conda-linux-gnu-c++ -MMD -MF ms_deform_attn_cpu.o.d -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/transformers/kernels/deformable_detr -isystem /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/torch/include -isystem /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/torch/include/TH -isystem /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/torch/include/THC -isystem /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -DWITH_CUDA=1 -c /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/transformers/kernels/deformable_detr/cpu/ms_deform_attn_cpu.cpp -o ms_deform_attn_cpu.o \n",
            "In file included from /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/torch/include/ATen/cuda/CUDAContext.h:3,\n",
            "                 from /home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/transformers/kernels/deformable_detr/cpu/ms_deform_attn_cpu.cpp:14:\n",
            "/home/sujee/apps/anaconda3/envs/dpk-3-pdf-processing-r1.1.0-py3.11/lib/python3.11/site-packages/torch/include/ATen/cuda/CUDAContextLight.h:6:10: fatal error: cuda_runtime_api.h: No such file or directory\n",
            "    6 | #include <cuda_runtime_api.h>\n",
            "      |          ^~~~~~~~~~~~~~~~~~~~\n",
            "compilation terminated.\n",
            "ninja: build stopped: subcommand failed.\n",
            "\n",
            "Could not load the custom kernel for multi-scale deformable attention: /home/sujee/.cache/torch_extensions/py311_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
            "Could not load the custom kernel for multi-scale deformable attention: /home/sujee/.cache/torch_extensions/py311_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
            "Could not load the custom kernel for multi-scale deformable attention: /home/sujee/.cache/torch_extensions/py311_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
            "Could not load the custom kernel for multi-scale deformable attention: /home/sujee/.cache/torch_extensions/py311_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
            "Could not load the custom kernel for multi-scale deformable attention: /home/sujee/.cache/torch_extensions/py311_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory\n",
            "12:05:46 INFO - Completed 1 files (20.0%) in 0.016 min\n",
            "12:05:46 INFO - Completed 2 files (40.0%) in 0.019 min\n",
            "12:05:46 INFO - Completed 3 files (60.0%) in 0.022 min\n",
            "12:05:47 INFO - Completed 4 files (80.0%) in 0.025 min\n",
            "12:05:47 INFO - Completed 5 files (100.0%) in 0.027 min\n",
            "12:05:47 INFO - Done processing 5 files, waiting for flush() completion.\n",
            "12:05:47 INFO - done flushing in 0.0 sec\n",
            "12:05:47 INFO - Completed execution in 0.136 min, execution result 0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Operation completed successfully\n",
            "CPU times: user 8.29 s, sys: 1.87 s, total: 10.2 s\n",
            "Wall time: 14 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "from dpk_pdf2parquet.transform_python import Pdf2Parquet\n",
        "from dpk_pdf2parquet.transform import pdf2parquet_contents_types\n",
        "\n",
        "print (f\"🏃🏼 Processing input='{input_dir}' --> output='{output_pdf2pq_dir}'\\n\", flush=True)\n",
        "\n",
        "result = Pdf2Parquet(input_folder= input_dir,\n",
        "                    output_folder= output_pdf2pq_dir,\n",
        "                    data_files_to_use=['.pdf'],\n",
        "                    pdf2parquet_contents_type=pdf2parquet_contents_types.MARKDOWN,   # markdown\n",
        "                    ).transform()\n",
        "\n",
        "if result == 0:\n",
        "    print (f\"✅ Operation completed successfully\")\n",
        "else:\n",
        "    raise Exception (f\"❌ Operation  failed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eraaot-5xcg2"
      },
      "source": [
        "### 4.2 - Inspect Generated output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "_9WmfE8Uxcg3",
        "outputId": "99198359-76f5-4542-b774-ee3bf2886ea2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Displaying contents of :  output/01_pdf2pq_out\n",
            "Successfully read 5 parquet files with 5 total rows\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>contents</th>\n",
              "      <th>num_pages</th>\n",
              "      <th>num_tables</th>\n",
              "      <th>num_doc_elements</th>\n",
              "      <th>document_id</th>\n",
              "      <th>document_hash</th>\n",
              "      <th>ext</th>\n",
              "      <th>hash</th>\n",
              "      <th>size</th>\n",
              "      <th>date_acquired</th>\n",
              "      <th>pdf_convert_time</th>\n",
              "      <th>source_filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hap3.pdf</td>\n",
              "      <td>## HAP Example - Hate (Mild)\\n\\nI hate all tal...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4640a2a1-bbef-4dff-870c-951df7e5ffab</td>\n",
              "      <td>14415754726703435224</td>\n",
              "      <td>pdf</td>\n",
              "      <td>61704194822aec595d2b38e8cbe223b3191c859dc8cfdc...</td>\n",
              "      <td>53</td>\n",
              "      <td>2025-03-26T12:05:47.035007</td>\n",
              "      <td>0.161497</td>\n",
              "      <td>hap3.pdf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hap4.pdf</td>\n",
              "      <td>## HAP Example\\n\\nI hate this traffic!</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7988fcc4-7763-4cfd-b91d-1d2b4c0e11e5</td>\n",
              "      <td>1118223425461926585</td>\n",
              "      <td>pdf</td>\n",
              "      <td>ebf223c519ac1c4e9c3702e89366ca0b2d131d5f6fbd5a...</td>\n",
              "      <td>36</td>\n",
              "      <td>2025-03-26T12:05:47.199717</td>\n",
              "      <td>0.163099</td>\n",
              "      <td>hap4.pdf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hap2.pdf</td>\n",
              "      <td>## HAP Example - Hate\\n\\nI hate all immigrants!</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>186d1e43-07a0-4e68-a41a-16c426cf236f</td>\n",
              "      <td>9456501710902741619</td>\n",
              "      <td>pdf</td>\n",
              "      <td>18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...</td>\n",
              "      <td>45</td>\n",
              "      <td>2025-03-26T12:05:46.871889</td>\n",
              "      <td>0.160447</td>\n",
              "      <td>hap2.pdf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hap1.pdf</td>\n",
              "      <td>## HAP example - Abuse and Profanity\\n\\nYou ar...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>a3c6dde1-4e6f-4e15-9e21-ea4497517f44</td>\n",
              "      <td>4197663060196400691</td>\n",
              "      <td>pdf</td>\n",
              "      <td>d1157451bf6b9b69c16bf89f05c06a0210497306236c72...</td>\n",
              "      <td>136</td>\n",
              "      <td>2025-03-26T12:05:46.709816</td>\n",
              "      <td>0.184696</td>\n",
              "      <td>hap1.pdf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>earth.pdf</td>\n",
              "      <td>## Earth\\n\\n## Solar System\\n\\nOur solar syste...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>c7b68ce5-8a50-4eb5-baf7-546580cd47c0</td>\n",
              "      <td>1139588115783882743</td>\n",
              "      <td>pdf</td>\n",
              "      <td>3766e7a7dfb15354f2a8c77e43db4cfa40d4627f921126...</td>\n",
              "      <td>611</td>\n",
              "      <td>2025-03-26T12:05:46.511357</td>\n",
              "      <td>0.945042</td>\n",
              "      <td>earth.pdf</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    filename                                           contents  num_pages  \\\n",
              "0   hap3.pdf  ## HAP Example - Hate (Mild)\\n\\nI hate all tal...          1   \n",
              "1   hap4.pdf             ## HAP Example\\n\\nI hate this traffic!          1   \n",
              "2   hap2.pdf    ## HAP Example - Hate\\n\\nI hate all immigrants!          1   \n",
              "3   hap1.pdf  ## HAP example - Abuse and Profanity\\n\\nYou ar...          1   \n",
              "4  earth.pdf  ## Earth\\n\\n## Solar System\\n\\nOur solar syste...          1   \n",
              "\n",
              "   num_tables  num_doc_elements                           document_id  \\\n",
              "0           0                 3  4640a2a1-bbef-4dff-870c-951df7e5ffab   \n",
              "1           0                 3  7988fcc4-7763-4cfd-b91d-1d2b4c0e11e5   \n",
              "2           0                 3  186d1e43-07a0-4e68-a41a-16c426cf236f   \n",
              "3           0                 4  a3c6dde1-4e6f-4e15-9e21-ea4497517f44   \n",
              "4           0                11  c7b68ce5-8a50-4eb5-baf7-546580cd47c0   \n",
              "\n",
              "          document_hash  ext  \\\n",
              "0  14415754726703435224  pdf   \n",
              "1   1118223425461926585  pdf   \n",
              "2   9456501710902741619  pdf   \n",
              "3   4197663060196400691  pdf   \n",
              "4   1139588115783882743  pdf   \n",
              "\n",
              "                                                hash  size  \\\n",
              "0  61704194822aec595d2b38e8cbe223b3191c859dc8cfdc...    53   \n",
              "1  ebf223c519ac1c4e9c3702e89366ca0b2d131d5f6fbd5a...    36   \n",
              "2  18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...    45   \n",
              "3  d1157451bf6b9b69c16bf89f05c06a0210497306236c72...   136   \n",
              "4  3766e7a7dfb15354f2a8c77e43db4cfa40d4627f921126...   611   \n",
              "\n",
              "                date_acquired  pdf_convert_time source_filename  \n",
              "0  2025-03-26T12:05:47.035007          0.161497        hap3.pdf  \n",
              "1  2025-03-26T12:05:47.199717          0.163099        hap4.pdf  \n",
              "2  2025-03-26T12:05:46.871889          0.160447        hap2.pdf  \n",
              "3  2025-03-26T12:05:46.709816          0.184696        hap1.pdf  \n",
              "4  2025-03-26T12:05:46.511357          0.945042       earth.pdf  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from file_utils import read_parquet_files_as_df\n",
        "\n",
        "print (\"Displaying contents of : \", output_pdf2pq_dir)\n",
        "output_df = read_parquet_files_as_df(output_pdf2pq_dir)\n",
        "output_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LmsMfRFxcg3",
        "outputId": "dd1e0b13-f4f1-4ceb-99f3-06f1c2084e6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## HAP example - Abuse and Profanity\n",
            "\n",
            "You are such an idiot for making these stupid decisions!\n",
            "\n",
            "you are such a complete f*cking failure!\n"
          ]
        }
      ],
      "source": [
        "print (output_df[output_df['filename'] == 'hap1.pdf'].iloc[0,]['contents'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NCMolCDOVBf",
        "outputId": "2b670518-ae15-40f9-dda1-4fa89bceba10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## HAP Example - Hate\n",
            "\n",
            "I hate all immigrants!\n"
          ]
        }
      ],
      "source": [
        "print (output_df[output_df['filename'] == 'hap2.pdf'].iloc[0,]['contents'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXlzGJ2yOVBf",
        "outputId": "aff8c224-2f92-41b1-f425-384ebd043b65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## HAP Example - Hate (Mild)\n",
            "\n",
            "I hate all tall people!\n"
          ]
        }
      ],
      "source": [
        "print (output_df[output_df['filename'] == 'hap3.pdf'].iloc[0,]['contents'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcxyrjrhTTB6",
        "outputId": "918c85cd-2764-40fd-f05e-5a3300e7fea2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## HAP Example\n",
            "\n",
            "I hate this traffic!\n"
          ]
        }
      ],
      "source": [
        "print (output_df[output_df['filename'] == 'hap4.pdf'].iloc[0,]['contents'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg5vYQq1OVBf"
      },
      "source": [
        "## Step-5: HAP Detector\n",
        "\n",
        "[HAP transform documentation](https://github.com/data-prep-kit/data-prep-kit/blob/dev/transforms/universal/hap/)\n",
        "\n",
        "Some parameters:\n",
        "\n",
        "- `model_name_or_path` - specify the HAP model, which should be compatible with HuggingFace's AutoModelForSequenceClassification. Defaults to IBM's open-source toxicity classifier **ibm-granite/granite-guardian-hap-38m**\n",
        "- `annotation_column` - the column name containing hap (toxicity) score in the output .parquet file. Defaults to hap_score.\n",
        "- `doc_text_column`- the column name containing the document text in the input .parquet file. Defaults to contents.\n",
        "- `batch_size` - modify it based on the infrastructure capacity. Defaults to 128.\n",
        "- `max_length` - the maximum length for the tokenizer. Defaults to 512.\n",
        "\n",
        "Here are HAP detection models\n",
        "\n",
        "- [ibm-granite/granite-guardian-hap-38m](https://huggingface.co/ibm-granite/granite-guardian-hap-38m)\n",
        "- [ibm-granite/granite-guardian-hap-125m](https://huggingface.co/ibm-granite/granite-guardian-hap-125m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 - Execute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDFokf28OVBg",
        "outputId": "ce82ebfc-807b-43ec-8191-1a0e0427f0a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /home/sujee/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "12:05:47 INFO - hap params are {'model_name_or_path': 'ibm-granite/granite-guardian-hap-38m', 'annotation_column': 'hap_score', 'doc_text_column': 'contents', 'inference_engine': 'CPU', 'max_length': 512, 'batch_size': 128} \n",
            "12:05:47 INFO - pipeline id pipeline_id\n",
            "12:05:47 INFO - code location None\n",
            "12:05:47 INFO - data factory data_ is using local data access: input_folder - output/01_pdf2pq_out output_folder - output/02_hap_out\n",
            "12:05:47 INFO - data factory data_ max_files -1, n_sample -1\n",
            "12:05:47 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
            "12:05:47 INFO - orchestrator hap started at 2025-03-26 12:05:47\n",
            "12:05:47 INFO - Number of files is 5, source profile {'max_file_size': 0.009408950805664062, 'min_file_size': 0.005721092224121094, 'total_file_size': 0.033120155334472656}\n",
            "12:05:49 INFO - Completed 1 files (20.0%) in 0.002 min\n",
            "12:05:49 INFO - Completed 2 files (40.0%) in 0.002 min\n",
            "12:05:49 INFO - Completed 3 files (60.0%) in 0.002 min\n",
            "12:05:49 INFO - Completed 4 files (80.0%) in 0.002 min\n",
            "12:05:49 INFO - Completed 5 files (100.0%) in 0.003 min\n",
            "12:05:49 INFO - Done processing 5 files, waiting for flush() completion.\n",
            "12:05:49 INFO - done flushing in 0.0 sec\n",
            "12:05:49 INFO - Completed execution in 0.02 min, execution result 0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch: 0/0\n",
            "    filename                                           contents  num_pages  \\\n",
            "0  earth.pdf  ## Earth\\n\\n## Solar System\\n\\nOur solar syste...          1   \n",
            "\n",
            "   num_tables  num_doc_elements                           document_id  \\\n",
            "0           0                11  c7b68ce5-8a50-4eb5-baf7-546580cd47c0   \n",
            "\n",
            "         document_hash  ext  \\\n",
            "0  1139588115783882743  pdf   \n",
            "\n",
            "                                                hash  size  \\\n",
            "0  3766e7a7dfb15354f2a8c77e43db4cfa40d4627f921126...   611   \n",
            "\n",
            "                date_acquired  pdf_convert_time source_filename  hap_score  \n",
            "0  2025-03-26T12:05:46.511357          0.945042       earth.pdf   0.000406  \n",
            "Processing batch: 0/0\n",
            "   filename                                           contents  num_pages  \\\n",
            "0  hap1.pdf  ## HAP example - Abuse and Profanity\\n\\nYou ar...          1   \n",
            "\n",
            "   num_tables  num_doc_elements                           document_id  \\\n",
            "0           0                 4  a3c6dde1-4e6f-4e15-9e21-ea4497517f44   \n",
            "\n",
            "         document_hash  ext  \\\n",
            "0  4197663060196400691  pdf   \n",
            "\n",
            "                                                hash  size  \\\n",
            "0  d1157451bf6b9b69c16bf89f05c06a0210497306236c72...   136   \n",
            "\n",
            "                date_acquired  pdf_convert_time source_filename  hap_score  \n",
            "0  2025-03-26T12:05:46.709816          0.184696        hap1.pdf   0.997993  \n",
            "Processing batch: 0/0\n",
            "   filename                                         contents  num_pages  \\\n",
            "0  hap2.pdf  ## HAP Example - Hate\\n\\nI hate all immigrants!          1   \n",
            "\n",
            "   num_tables  num_doc_elements                           document_id  \\\n",
            "0           0                 3  186d1e43-07a0-4e68-a41a-16c426cf236f   \n",
            "\n",
            "         document_hash  ext  \\\n",
            "0  9456501710902741619  pdf   \n",
            "\n",
            "                                                hash  size  \\\n",
            "0  18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...    45   \n",
            "\n",
            "                date_acquired  pdf_convert_time source_filename  hap_score  \n",
            "0  2025-03-26T12:05:46.871889          0.160447        hap2.pdf    0.90329  \n",
            "Processing batch: 0/0\n",
            "   filename                                           contents  num_pages  \\\n",
            "0  hap3.pdf  ## HAP Example - Hate (Mild)\\n\\nI hate all tal...          1   \n",
            "\n",
            "   num_tables  num_doc_elements                           document_id  \\\n",
            "0           0                 3  4640a2a1-bbef-4dff-870c-951df7e5ffab   \n",
            "\n",
            "          document_hash  ext  \\\n",
            "0  14415754726703435224  pdf   \n",
            "\n",
            "                                                hash  size  \\\n",
            "0  61704194822aec595d2b38e8cbe223b3191c859dc8cfdc...    53   \n",
            "\n",
            "                date_acquired  pdf_convert_time source_filename  hap_score  \n",
            "0  2025-03-26T12:05:47.035007          0.161497        hap3.pdf   0.359412  \n",
            "Processing batch: 0/0\n",
            "   filename                                contents  num_pages  num_tables  \\\n",
            "0  hap4.pdf  ## HAP Example\\n\\nI hate this traffic!          1           0   \n",
            "\n",
            "   num_doc_elements                           document_id  \\\n",
            "0                 3  7988fcc4-7763-4cfd-b91d-1d2b4c0e11e5   \n",
            "\n",
            "         document_hash  ext  \\\n",
            "0  1118223425461926585  pdf   \n",
            "\n",
            "                                                hash  size  \\\n",
            "0  ebf223c519ac1c4e9c3702e89366ca0b2d131d5f6fbd5a...    36   \n",
            "\n",
            "                date_acquired  pdf_convert_time source_filename  hap_score  \n",
            "0  2025-03-26T12:05:47.199717          0.163099        hap4.pdf    0.00148  \n",
            "✅ Operation completed successfully\n"
          ]
        }
      ],
      "source": [
        "from dpk_hap.transform_python import HAP\n",
        "\n",
        "\n",
        "result = HAP(input_folder= output_pdf2pq_dir,\n",
        "        output_folder= output_hap_dir,\n",
        "        model_name_or_path= 'ibm-granite/granite-guardian-hap-38m',\n",
        "        annotation_column= \"hap_score\",\n",
        "        doc_text_column= \"contents\",\n",
        "        inference_engine= \"CPU\",\n",
        "        max_length= 512,\n",
        "        batch_size= 128,\n",
        "        ).transform()\n",
        "\n",
        "if result == 0:\n",
        "    print (f\"✅ Operation completed successfully\")\n",
        "else:\n",
        "    raise Exception (f\"❌ Operation  failed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJ0jpaFOxcg4"
      },
      "source": [
        "### 5.2 - Inspect Generated output\n",
        "\n",
        "Let's see the output.  Inspect **hap_score** output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "cTQymlusxcg4",
        "outputId": "f59bb859-e9ef-4048-e64e-03938bf00007"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Displaying contents of :  output/02_hap_out\n",
            "Successfully read 5 parquet files with 5 total rows\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>contents</th>\n",
              "      <th>num_pages</th>\n",
              "      <th>num_tables</th>\n",
              "      <th>num_doc_elements</th>\n",
              "      <th>document_id</th>\n",
              "      <th>document_hash</th>\n",
              "      <th>ext</th>\n",
              "      <th>hash</th>\n",
              "      <th>size</th>\n",
              "      <th>date_acquired</th>\n",
              "      <th>pdf_convert_time</th>\n",
              "      <th>source_filename</th>\n",
              "      <th>hap_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hap3.pdf</td>\n",
              "      <td>## HAP Example - Hate (Mild)\\n\\nI hate all tal...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4640a2a1-bbef-4dff-870c-951df7e5ffab</td>\n",
              "      <td>14415754726703435224</td>\n",
              "      <td>pdf</td>\n",
              "      <td>61704194822aec595d2b38e8cbe223b3191c859dc8cfdc...</td>\n",
              "      <td>53</td>\n",
              "      <td>2025-03-26T12:05:47.035007</td>\n",
              "      <td>0.161497</td>\n",
              "      <td>hap3.pdf</td>\n",
              "      <td>0.359412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hap4.pdf</td>\n",
              "      <td>## HAP Example\\n\\nI hate this traffic!</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7988fcc4-7763-4cfd-b91d-1d2b4c0e11e5</td>\n",
              "      <td>1118223425461926585</td>\n",
              "      <td>pdf</td>\n",
              "      <td>ebf223c519ac1c4e9c3702e89366ca0b2d131d5f6fbd5a...</td>\n",
              "      <td>36</td>\n",
              "      <td>2025-03-26T12:05:47.199717</td>\n",
              "      <td>0.163099</td>\n",
              "      <td>hap4.pdf</td>\n",
              "      <td>0.001480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hap2.pdf</td>\n",
              "      <td>## HAP Example - Hate\\n\\nI hate all immigrants!</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>186d1e43-07a0-4e68-a41a-16c426cf236f</td>\n",
              "      <td>9456501710902741619</td>\n",
              "      <td>pdf</td>\n",
              "      <td>18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...</td>\n",
              "      <td>45</td>\n",
              "      <td>2025-03-26T12:05:46.871889</td>\n",
              "      <td>0.160447</td>\n",
              "      <td>hap2.pdf</td>\n",
              "      <td>0.903290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hap1.pdf</td>\n",
              "      <td>## HAP example - Abuse and Profanity\\n\\nYou ar...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>a3c6dde1-4e6f-4e15-9e21-ea4497517f44</td>\n",
              "      <td>4197663060196400691</td>\n",
              "      <td>pdf</td>\n",
              "      <td>d1157451bf6b9b69c16bf89f05c06a0210497306236c72...</td>\n",
              "      <td>136</td>\n",
              "      <td>2025-03-26T12:05:46.709816</td>\n",
              "      <td>0.184696</td>\n",
              "      <td>hap1.pdf</td>\n",
              "      <td>0.997993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>earth.pdf</td>\n",
              "      <td>## Earth\\n\\n## Solar System\\n\\nOur solar syste...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>c7b68ce5-8a50-4eb5-baf7-546580cd47c0</td>\n",
              "      <td>1139588115783882743</td>\n",
              "      <td>pdf</td>\n",
              "      <td>3766e7a7dfb15354f2a8c77e43db4cfa40d4627f921126...</td>\n",
              "      <td>611</td>\n",
              "      <td>2025-03-26T12:05:46.511357</td>\n",
              "      <td>0.945042</td>\n",
              "      <td>earth.pdf</td>\n",
              "      <td>0.000406</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    filename                                           contents  num_pages  \\\n",
              "0   hap3.pdf  ## HAP Example - Hate (Mild)\\n\\nI hate all tal...          1   \n",
              "1   hap4.pdf             ## HAP Example\\n\\nI hate this traffic!          1   \n",
              "2   hap2.pdf    ## HAP Example - Hate\\n\\nI hate all immigrants!          1   \n",
              "3   hap1.pdf  ## HAP example - Abuse and Profanity\\n\\nYou ar...          1   \n",
              "4  earth.pdf  ## Earth\\n\\n## Solar System\\n\\nOur solar syste...          1   \n",
              "\n",
              "   num_tables  num_doc_elements                           document_id  \\\n",
              "0           0                 3  4640a2a1-bbef-4dff-870c-951df7e5ffab   \n",
              "1           0                 3  7988fcc4-7763-4cfd-b91d-1d2b4c0e11e5   \n",
              "2           0                 3  186d1e43-07a0-4e68-a41a-16c426cf236f   \n",
              "3           0                 4  a3c6dde1-4e6f-4e15-9e21-ea4497517f44   \n",
              "4           0                11  c7b68ce5-8a50-4eb5-baf7-546580cd47c0   \n",
              "\n",
              "          document_hash  ext  \\\n",
              "0  14415754726703435224  pdf   \n",
              "1   1118223425461926585  pdf   \n",
              "2   9456501710902741619  pdf   \n",
              "3   4197663060196400691  pdf   \n",
              "4   1139588115783882743  pdf   \n",
              "\n",
              "                                                hash  size  \\\n",
              "0  61704194822aec595d2b38e8cbe223b3191c859dc8cfdc...    53   \n",
              "1  ebf223c519ac1c4e9c3702e89366ca0b2d131d5f6fbd5a...    36   \n",
              "2  18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...    45   \n",
              "3  d1157451bf6b9b69c16bf89f05c06a0210497306236c72...   136   \n",
              "4  3766e7a7dfb15354f2a8c77e43db4cfa40d4627f921126...   611   \n",
              "\n",
              "                date_acquired  pdf_convert_time source_filename  hap_score  \n",
              "0  2025-03-26T12:05:47.035007          0.161497        hap3.pdf   0.359412  \n",
              "1  2025-03-26T12:05:47.199717          0.163099        hap4.pdf   0.001480  \n",
              "2  2025-03-26T12:05:46.871889          0.160447        hap2.pdf   0.903290  \n",
              "3  2025-03-26T12:05:46.709816          0.184696        hap1.pdf   0.997993  \n",
              "4  2025-03-26T12:05:46.511357          0.945042       earth.pdf   0.000406  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from file_utils import read_parquet_files_as_df\n",
        "\n",
        "print (\"Displaying contents of : \", output_hap_dir)\n",
        "output_df = read_parquet_files_as_df(output_hap_dir)\n",
        "output_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wV-70IbeOVBg",
        "outputId": "3b8deb9f-f0b4-4f7f-84af-2e07640cbdae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>contents</th>\n",
              "      <th>hap_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hap3.pdf</td>\n",
              "      <td>## HAP Example - Hate (Mild)\\n\\nI hate all tal...</td>\n",
              "      <td>0.359412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hap4.pdf</td>\n",
              "      <td>## HAP Example\\n\\nI hate this traffic!</td>\n",
              "      <td>0.001480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hap2.pdf</td>\n",
              "      <td>## HAP Example - Hate\\n\\nI hate all immigrants!</td>\n",
              "      <td>0.903290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hap1.pdf</td>\n",
              "      <td>## HAP example - Abuse and Profanity\\n\\nYou ar...</td>\n",
              "      <td>0.997993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>earth.pdf</td>\n",
              "      <td>## Earth\\n\\n## Solar System\\n\\nOur solar syste...</td>\n",
              "      <td>0.000406</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    filename                                           contents  hap_score\n",
              "0   hap3.pdf  ## HAP Example - Hate (Mild)\\n\\nI hate all tal...   0.359412\n",
              "1   hap4.pdf             ## HAP Example\\n\\nI hate this traffic!   0.001480\n",
              "2   hap2.pdf    ## HAP Example - Hate\\n\\nI hate all immigrants!   0.903290\n",
              "3   hap1.pdf  ## HAP example - Abuse and Profanity\\n\\nYou ar...   0.997993\n",
              "4  earth.pdf  ## Earth\\n\\n## Solar System\\n\\nOur solar syste...   0.000406"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_df[['filename', 'contents', 'hap_score']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLwJFXalOVBg"
      },
      "source": [
        "## Step-6: Extract Clean Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "00_yngakOVBg",
        "outputId": "d79fd2a7-d08c-406f-cb57-e9c4edbc70bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully read 5 parquet files with 5 total rows\n",
            "clean documents\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>contents</th>\n",
              "      <th>hap_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hap4.pdf</td>\n",
              "      <td>## HAP Example\\n\\nI hate this traffic!</td>\n",
              "      <td>0.001480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>earth.pdf</td>\n",
              "      <td>## Earth\\n\\n## Solar System\\n\\nOur solar syste...</td>\n",
              "      <td>0.000406</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    filename                                           contents  hap_score\n",
              "1   hap4.pdf             ## HAP Example\\n\\nI hate this traffic!   0.001480\n",
              "4  earth.pdf  ## Earth\\n\\n## Solar System\\n\\nOur solar syste...   0.000406"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from file_utils import read_parquet_files_as_df\n",
        "\n",
        "hap_output_df = read_parquet_files_as_df(output_hap_dir)\n",
        "clean_docs_df = hap_output_df[hap_output_df['hap_score'] < 0.2]\n",
        "\n",
        "print ('clean documents')\n",
        "clean_docs_df[['filename', 'contents', 'hap_score']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqRhROr-xcg4"
      },
      "source": [
        "## Step-7: Save as MD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls262snN4gFe",
        "outputId": "f34b3fd1-4720-4a5c-c4c6-99e4916f1189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved CLEAN markdown output to 'output/03_md'\n"
          ]
        }
      ],
      "source": [
        "for index, row in clean_docs_df.iterrows():\n",
        "    output_file_name = os.path.join (output_md_dir, row['filename'] + '.md')\n",
        "    with open(output_file_name, 'w') as output_file:\n",
        "        output_file.write(row['contents'])\n",
        "\n",
        "print (f\"✅ Saved CLEAN markdown output to '{output_md_dir}'\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dpk-3-pdf-processing-r1.1.0-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
