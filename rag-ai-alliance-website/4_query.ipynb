{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG on HTML documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_config import MY_CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2: Setup Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If connection to https://huggingface.co/ failed, uncomment the following path\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name = MY_CONFIG.EMBEDDING_MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3: Connect to Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 14:51:16,773 [DEBUG][_create_connection]: Created new connection using: 193303c7b1f141e1813524782ffd77fc (async_milvus_client.py:600)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to Milvus instance:  ./rag_website.db\n"
     ]
    }
   ],
   "source": [
    "# connect to vector db\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "\n",
    "vector_store = MilvusVectorStore(\n",
    "    uri = MY_CONFIG.DB_URI ,\n",
    "    dim = MY_CONFIG.EMBEDDING_LENGTH , \n",
    "    collection_name = MY_CONFIG.COLLECTION_NAME,\n",
    "    overwrite=False  # so we load the index from db\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "print (\"✅ Connected to Milvus instance: \", MY_CONFIG.DB_URI )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-4: Load Document Index from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded index from vector db: ./rag_website.db\n",
      "CPU times: user 99.2 ms, sys: 18.8 ms, total: 118 ms\n",
      "Wall time: 127 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, storage_context=storage_context)\n",
    "\n",
    "print (\"✅ Loaded index from vector db:\", MY_CONFIG.DB_URI )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-5: Setup LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.replicate import Replicate\n",
    "from llama_index.core import Settings\n",
    "\n",
    "llm = Replicate(\n",
    "    model= MY_CONFIG.LLM_MODEL,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-6: Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AI Alliance is an international community of developers, researchers, and organizations dedicated to promoting open, safe, and responsible artificial intelligence. It was launched in December 2023 and emphasizes the importance of open technologies, encouraging their adoption across various sectors to foster an environment where AI can thrive and benefit people and society worldwide. The Alliance brings together a diverse mix of academia, startups, enterprises, and scientific organizations from around the globe. It has established two member-driven working groups, AI Safety and Trust Tooling, and AI Policy Advocacy, to address challenges in generative AI and democratize its benefits. The AI Alliance also manages Core Projects and Affiliated Projects, with Core Projects being foundational building blocks and managed directly by the Alliance, while Affiliated Projects are typically from member organizations seeking deeper collaboration and impact.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "res = query_engine.query(\"What is AI Alliance?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the AI Alliance has six goal-oriented thematic programs, which are referred to as Focus Areas. These Focus Areas are:\n",
      "\n",
      "1. Foundational Capabilities\n",
      "2. Safety\n",
      "3. Security\n",
      "4. Trust\n",
      "5. Responsible AI Development\n",
      "6. Maximizing Benefits to People and Society\n",
      "\n",
      "These Focus Areas guide the AI Alliance's efforts in deploying benchmarks, tools, and resources for responsible AI development and use at a global scale. They also support the advancement of open foundation models with diverse modalities and foster a vibrant AI hardware accelerator ecosystem. Additionally, the AI Alliance focuses on global AI skills building, education, and exploratory research, as well as developing educational content and resources for the public and policymakers.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "res = query_engine.query(\"What are the main focus areas of AI Alliance?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the AI Alliance members plan to start or enhance projects with the following objectives:\n",
      "\n",
      "1. Deploying benchmarks, tools, and resources for responsible AI development and use at a global scale, including creating a catalog of vetted safety, security, and trust tools.\n",
      "2. Advancing the ecosystem of open foundation models with diverse modalities, such as multilingual, multi-modal, and science models, to address societal challenges.\n",
      "3. Fostering a vibrant AI hardware accelerator ecosystem by boosting contributions and adoption of essential enabling software technology.\n",
      "4. Supporting global AI skills building, education, and exploratory research, engaging the academic community to support AI model and tool research projects.\n",
      "5. Developing educational content and resources to inform the public and policymakers about AI's benefits, risks, solutions, and precision regulation.\n",
      "6. Launching initiatives that encourage open development of AI in safe and beneficial ways, and hosting events to explore AI use cases and showcase responsible AI applications.\n",
      "\n",
      "These projects are categorized as Core Projects, which are managed directly by the AI Alliance and governed according to the defined governance structure. Affiliated Projects, which are typically from member organizations seeking deeper collaboration, are also part of the AI Alliance's initiatives but retain full management of the project.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "res = query_engine.query(\"What are some ai alliance projects?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The demo night was held in San Francisco, California.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "res = query_engine.query(\"Where was the demo night held?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The context information provided does not contain any details about the moon landing. It discusses two AI-related projects: LLM360 and Lightning AI's open-source frameworks for GenAI builders. The first project involves releasing various components of a large language model (LLM) initiative, while the second project focuses on maintaining and expanding open-source tools for deep learning and GenAI. Neither of these projects mentions the moon landing.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "res = query_engine.query(\"When was the moon landing?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-website-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
