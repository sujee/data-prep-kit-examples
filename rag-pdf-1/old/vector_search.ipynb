{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handy Utils to do Vector Search on Collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConfig:\n",
    "    pass\n",
    "MY_CONFIG = MyConfig()\n",
    "\n",
    "## This has to match the embeddings the documents are stored in vectordb!\n",
    "MY_CONFIG.EMBEDDING_MODEL = \"BAAI/bge-small-en-v1.5\"\n",
    "MY_CONFIG.EMBEDDING_LENGTH = 384\n",
    "\n",
    "MY_CONFIG.DB_URI = './rag_demo_dataprepkit_1.db'  # For embedded instance\n",
    "#MY_CONFIG.DB_URI = 'http://localhost:19530'  # For Docker instance\n",
    "MY_CONFIG.COLLECTION_NAME = 'dataprepkit_granite_docs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Vector Database\n",
    "\n",
    "Milvus can be embedded and easy to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to Milvus instance: ./rag_demo_dataprepkit_1.db\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "milvus_client = MilvusClient(MY_CONFIG.DB_URI)\n",
    "\n",
    "print (\"✅ Connected to Milvus instance:\", MY_CONFIG.DB_URI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Embeddings\n",
    "\n",
    "Two choices here. \n",
    "\n",
    "1. use sentence transformers directly\n",
    "2. use Milvus model wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sujee/apps/anaconda3/envs/data-prep-kit-dev-1/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "## Option 1 - use sentence transformers directly\n",
    "\n",
    "# If connection to https://huggingface.co/ failed, uncomment the following path\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(MY_CONFIG.EMBEDDING_MODEL)\n",
    "\n",
    "def get_embeddings (str):\n",
    "    embeddings = embedding_model.encode(str, normalize_embeddings=True)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Option 2 - Milvus model\n",
    "from pymilvus import model\n",
    "\n",
    "# If connection to https://huggingface.co/ failed, uncomment the following path\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "\n",
    "# embedding_fn = model.DefaultEmbeddingFunction()\n",
    "\n",
    "## initialize the SentenceTransformerEmbeddingFunction\n",
    "embedding_fn = model.dense.SentenceTransformerEmbeddingFunction(\n",
    "    model_name = MY_CONFIG.EMBEDDING_MODEL,\n",
    "    device='cpu' # this will work on all devices (KIS)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence transformer : embeddings len = 384\n",
      "sentence transformer : embeddings[:5] =  [-0.02412123 -0.02083506  0.03565466  0.00688349  0.02383429]\n",
      "milvus model wrapper : embeddings len = 384\n",
      "milvus model wrapper  : embeddings[:5] =  [-0.02412122 -0.0208351   0.03565468  0.00688352  0.02383425]\n"
     ]
    }
   ],
   "source": [
    "# Test Embeddings\n",
    "text = 'Paris 2024 Olympics'\n",
    "embeddings = get_embeddings(text)\n",
    "print ('sentence transformer : embeddings len =', len(embeddings))\n",
    "print ('sentence transformer : embeddings[:5] = ', embeddings[:5])\n",
    "\n",
    "embeddings = embedding_fn([text])\n",
    "print ('milvus model wrapper : embeddings len =', len(embeddings[0]))\n",
    "print ('milvus model wrapper  : embeddings[:5] = ', embeddings[0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do A  Vector Search\n",
    "\n",
    "We will do this to verify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "## helper function to perform vector search\n",
    "def  do_vector_search (query):\n",
    "    query_vectors = [get_embeddings(query)]  # Option 1 - using sentence transformers\n",
    "    # query_vectors = embedding_fn([query])  # using Milvus model \n",
    "\n",
    "    results = milvus_client.search(\n",
    "        collection_name=MY_CONFIG.COLLECTION_NAME,  # target collection\n",
    "        data=query_vectors,  # query vectors\n",
    "        limit=5,  # number of returned entities\n",
    "        output_fields=[\"filename\", \"page_number\", \"text\"],  # specifies fields to be returned\n",
    "    )\n",
    "    return results\n",
    "## ----\n",
    "\n",
    "def  print_search_results (results):\n",
    "    # pprint (results)\n",
    "    print ('num results : ', len(results[0]))\n",
    "\n",
    "    for i, r in enumerate (results[0]):\n",
    "        #pprint(r, indent=4)\n",
    "        print (f'------ result {i+1} --------')\n",
    "        print ('search score:', r['distance'])\n",
    "        print ('filename:', r['entity']['filename'])\n",
    "        print ('page number:', r['entity']['page_number'])\n",
    "        print ('text:\\n', r['entity']['text'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num results :  5\n",
      "------ result 1 --------\n",
      "search score: 0.8775781989097595\n",
      "filename: Granite_Foundation_Models.pdf\n",
      "page number: 9\n",
      "text:\n",
      " B. Granite Model Evaluation and Comparison\n",
      "TABLE II GRANITE.13B GENERAL KNOWLEDGE PERFORMANCE DURING TRAINING\n",
      "\n",
      "------ result 2 --------\n",
      "search score: 0.8280450105667114\n",
      "filename: Granite_Foundation_Models.pdf\n",
      "page number: 9\n",
      "text:\n",
      " B. Granite Model Evaluation and Comparison\n",
      "For the SocialStigmaQA benchmark, we tested a variety of the Granite, llama-2, and flan-ul2 models. We examine whether the inclusion of specific personal attributes in the prompt leads\n",
      "\n",
      "------ result 3 --------\n",
      "search score: 0.8216305375099182\n",
      "filename: Granite_Foundation_Models.pdf\n",
      "page number: 8\n",
      "text:\n",
      " B. Granite Model Evaluation and Comparison\n",
      "Fig. 6. Granite.13b General Knowledge Performance during Training.\n",
      "\n",
      "------ result 4 --------\n",
      "search score: 0.8175002336502075\n",
      "filename: Granite_Foundation_Models.pdf\n",
      "page number: 2\n",
      "text:\n",
      " C. Organization of Report\n",
      "The remainder of this report is organized as follows. In Section II, we describe the data sources used in granite.13b's pre-training. In Section III, we describe the data processing steps we undertake with a focus on the governance steps we follow. In Section IV, we provide further details about the pre-training and fine-tuning algorithms, the computation involved, and the energy consumption we estimate. Section V presents the testing and evaluation framework along with quantitative comparisons to other models. In Section VI, we discuss our approach to understanding and mitigating sociotechnical harms from the Granite models. Section VII provides a brief discussion of the usage policies and the socio-technical documentation of Granite models. Finally in Section VIII, we conclude with areas of future work and discussion.\n",
      "\n",
      "------ result 5 --------\n",
      "search score: 0.8016891479492188\n",
      "filename: Granite_Foundation_Models.pdf\n",
      "page number: 4\n",
      "text:\n",
      " IV. TRAINING\n",
      "In this section, we detail the training process for the decoderonly Granite models covering the algorithmic details of pretraining and fine-tuning, the computing involved, and an estimate of the carbon footprint.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Overview of the Granite Pre-Training Dataset\"\n",
    "\n",
    "results = do_vector_search (query)\n",
    "print_search_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num results :  5\n",
      "------ result 1 --------\n",
      "search score: 0.812159538269043\n",
      "filename: Granite_Foundation_Models.pdf\n",
      "page number: 4\n",
      "text:\n",
      " B. Pre-Processing Pipeline\n",
      "2) Data De-Duplication: Data de-duplication aims to identify and remove duplicate documents. De-duplication is performed on a per-dataset basis and is essential to ensuring the trained model does not learn artificial linguistic patterns due to repeated data in the dataset.\n",
      "\n",
      "------ result 2 --------\n",
      "search score: 0.7404550909996033\n",
      "filename: Granite_Foundation_Models.pdf\n",
      "page number: 4\n",
      "text:\n",
      " B. Pre-Processing Pipeline\n",
      "Two techniques are used: exact and fuzzy de-duplication, both of which use hash-based methods. As the name suggests, exact de-duplication removes exact duplicates among the documents in the dataset. Each document is hashed and documents with the same hash are fused to one. For example, if 50 documents in a dataset have the same hash, a single document will be used. Fuzzy de-duplication finds the Jaccard similarity between documents with locality sensitive hashing. If multiple updated snapshots of a dataset are downloaded, the exact deduplication is performed across all snapshots.\n",
      "\n",
      "------ result 3 --------\n",
      "search score: 0.6455223560333252\n",
      "filename: Granite_Foundation_Models.pdf\n",
      "page number: 3\n",
      "text:\n",
      " A. Data Clearance and Acquisition\n",
      "Fig. 3. IBM's Data pre-processing pipeline.\n",
      "\n",
      "------ result 4 --------\n",
      "search score: 0.6397523880004883\n",
      "filename: Granite_Foundation_Models.pdf\n",
      "page number: 2\n",
      "text:\n",
      " II. DATA SOURCES\n",
      "5) GitHub Clean: Code data from CodeParrot covering a variety of coding languages.\n",
      "\n",
      "------ result 5 --------\n",
      "search score: 0.627116322517395\n",
      "filename: Granite_Foundation_Models.pdf\n",
      "page number: 3\n",
      "text:\n",
      " III. DATA GOVERNANCE\n",
      "A. Data clearance and acquisition;\n",
      "B. Pre-processing; and\n",
      "C. Tokenization.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"How is data de-duplicated?\"\n",
    "\n",
    "results = do_vector_search (query)\n",
    "print_search_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "milvus_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-prep-kit-dev-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
