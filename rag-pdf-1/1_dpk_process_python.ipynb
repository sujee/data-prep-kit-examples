{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "841e533d-ebb3-406d-9da7-b19e2c5f5866",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #04D7FD; padding: 20px; text-align: left;\">\n",
    "    <h1 style=\"color: #000000; font-size: 36px; margin: 0;\">Data Processing for RAG with Data Prep Kit (Python)</h1>\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15976e3",
   "metadata": {},
   "source": [
    "## Before Running the notebook\n",
    "\n",
    "Please complete [setting up python dev environment](./setup-python-dev-env.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053ecf08-5f62-4b99-9347-8a0955843d21",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook will process PDF documents as part of RAG pipeline\n",
    "\n",
    "### RAG Overview\n",
    "\n",
    "![](media/rag-overview-2.png)\n",
    "\n",
    "### PDF processing / cleaning\n",
    "\n",
    "This notebook will perform step 1 RAG pipeline.\n",
    "\n",
    "Here is the workflow:\n",
    "\n",
    "- docling2parquet: Extract text from PDF documents\n",
    "- docid: compute hashes\n",
    "- exact dedupe : filter out identical documents\n",
    "- fuzzy dedupe : filter out 'near duplicates'\n",
    "- document quality: scoring documents for quality\n",
    "- HAP (Hate Abuse Profanity) detector for filterig out HAP speech\n",
    "\n",
    "![](https://raw.githubusercontent.com/data-prep-kit/data-prep-kit/dev/examples/pdf-processing-1/images/data-prep-kit-3-workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b10be1",
   "metadata": {},
   "source": [
    "## Step-1: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33345487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_config import MY_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8902eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup path to utils folder\n",
    "import sys\n",
    "sys.path.append('../utils')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facb3bbc",
   "metadata": {},
   "source": [
    "## Step-2:  Data\n",
    "\n",
    "We will use white papers  about LLMs.  \n",
    "\n",
    "- [Granite Code Models](https://arxiv.org/abs/2405.04324)\n",
    "- [Attention is all you need](https://arxiv.org/abs/1706.03762)\n",
    "\n",
    "You can of course substite your own data below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fe7c0c",
   "metadata": {},
   "source": [
    "### 2.1 - data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9443714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using input folder: data\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import shutil\n",
    "from file_utils import download_file\n",
    "\n",
    "print (\"Using input folder:\", MY_CONFIG.INPUT_DATA_DIR)\n",
    "\n",
    "if not os.path.exists(MY_CONFIG.INPUT_DATA_DIR ):\n",
    "    raise Exception (f\"‚ùå Input folder MY_CONFIG.INPUT_DATA_DIR = '{MY_CONFIG.INPUT_DATA_DIR}' not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72510ae6-48b0-4b88-9e13-a623281c3a63",
   "metadata": {},
   "source": [
    "### 2.2 - Set input/output path variables for the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ac8bee-0960-4309-b225-d7a211b14262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using output directory: output\n",
      "‚úÖ Cleared output directory\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import shutil\n",
    "\n",
    "print (\"Using output directory:\", MY_CONFIG.OUTPUT_FOLDER)\n",
    "\n",
    "## clear output folder\n",
    "shutil.rmtree(MY_CONFIG.OUTPUT_FOLDER, ignore_errors=True)\n",
    "shutil.os.makedirs(MY_CONFIG.OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "print (\"‚úÖ Cleared output directory\")\n",
    "\n",
    "\n",
    "output_docling2pq_dir = os.path.join (MY_CONFIG.OUTPUT_FOLDER, '1_docling2pq_out')\n",
    "output_docid_dir = os.path.join (MY_CONFIG.OUTPUT_FOLDER, '2_docid_out')\n",
    "output_exact_dedupe_dir = os.path.join (MY_CONFIG.OUTPUT_FOLDER, '3_exact_dedupe_out')\n",
    "output_fuzzy_dedupe_dir = os.path.join (MY_CONFIG.OUTPUT_FOLDER, '4_fuzzy_dedupe_out')\n",
    "output_doc_quality_dir = os.path.join (MY_CONFIG.OUTPUT_FOLDER, '5_doc_quality_out')\n",
    "output_doc_quality_clean_dir = os.path.join (MY_CONFIG.OUTPUT_FOLDER, '6_doc_quality_clean_out')\n",
    "output_hap_detection_dir = os.path.join (MY_CONFIG.OUTPUT_FOLDER, '7_hap_detection_out')\n",
    "output_final_dir = os.path.join (MY_CONFIG.OUTPUT_FOLDER, 'output_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2449e5c7-078c-4ad6-a2f6-21d39d4da3fb",
   "metadata": {},
   "source": [
    "## Step-3: docling2parquet -  Convert data from PDF to Parquet\n",
    "\n",
    "This step is reading the input folder containing all PDF files and ingest them in a parquet table using the [Docling package](https://github.com/DS4SD/docling).\n",
    "The documents are converted into a JSON format which allows to easily chunk it in the later steps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb15f02-ab5c-4525-a536-cfa1fd2ba70b",
   "metadata": {},
   "source": [
    "### 3.1 - Execute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b101999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉüèº STAGE-1: Processing input='data' --> output='output/1_docling2pq_out'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"time\": \"22:22:07\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"docling2parquet parameters are : {'batch_size': -1, 'artifacts_path': None, 'contents_type': <docling2parquet_contents_types.MARKDOWN: 'text/markdown'>, 'do_table_structure': True, 'do_ocr': True, 'ocr_engine': <docling2parquet_ocr_engine.EASYOCR: 'easyocr'>, 'bitmap_area_threshold': 0.05, 'pdf_backend': <docling2parquet_pdf_backend.DLPARSE_V2: 'dlparse_v2'>, 'double_precision': 8, 'pipeline': <docling2parquet_pipeline.MULTI_STAGE: 'multi_stage'>, 'generate_picture_images': False, 'generate_page_images': False, 'images_scale': 2.0}\"}\n",
      "{\"time\": \"22:22:07\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"pipeline id pipeline_id\"}\n",
      "{\"time\": \"22:22:07\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"code location {'github': 'UNDEFINED', 'build-date': 'UNDEFINED', 'commit_hash': 'UNDEFINED', 'path': 'UNDEFINED'}\"}\n",
      "{\"time\": \"22:22:07\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ max_files -1, n_sample -1\"}\n",
      "{\"time\": \"22:22:07\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.pdf'], files to checkpoint ['.parquet']\"}\n",
      "{\"time\": \"22:22:07\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ Data Access:  DataAccessLocal\"}\n",
      "{\"time\": \"22:22:07\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"orchestrator docling2parquet started at 2025-11-19 22:22:07\"}\n",
      "{\"time\": \"22:22:07\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Number of files is 8, source profile {'max_file_size': 2.112621307373047, 'min_file_size': 0.023715972900390625, 'total_file_size': 5.43000602722168}\"}\n",
      "{\"time\": \"22:22:07\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Initializing models\"}\n",
      "2025-11-19 22:22:07,736 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 697e701a0d70f094f909a26604124fe1\n",
      "2025-11-19 22:22:07,744 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-11-19 22:22:07,745 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-11-19 22:22:07,753 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-11-19 22:22:07,755 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2025-11-19 22:22:07,810 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-19 22:22:09,077 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-19 22:22:10,025 - INFO - Accelerator device: 'cpu'\n",
      "2025-11-19 22:22:10,253 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-11-19 22:22:10,292 - INFO - Going to convert document batch...\n",
      "2025-11-19 22:22:10,293 - INFO - Processing document attention.pdf\n",
      "2025-11-19 22:22:45,846 - INFO - Finished converting document attention.pdf in 35.59 sec.\n",
      "{\"time\": \"22:22:45\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 1 files (12.5%) in 0.594 min\"}\n",
      "2025-11-19 22:22:45,889 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-11-19 22:22:45,892 - INFO - Going to convert document batch...\n",
      "2025-11-19 22:22:45,893 - INFO - Processing document granite-duplicate.pdf\n",
      "2025-11-19 22:25:11,112 - INFO - Finished converting document granite-duplicate.pdf in 145.22 sec.\n",
      "{\"time\": \"22:25:11\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 2 files (25.0%) in 3.015 min\"}\n",
      "2025-11-19 22:25:11,171 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-11-19 22:25:11,174 - INFO - Going to convert document batch...\n",
      "2025-11-19 22:25:11,174 - INFO - Processing document granite-similar.pdf\n",
      "2025-11-19 22:27:35,235 - INFO - Finished converting document granite-similar.pdf in 144.06 sec.\n",
      "{\"time\": \"22:27:35\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 3 files (37.5%) in 5.417 min\"}\n",
      "2025-11-19 22:27:35,290 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-11-19 22:27:35,293 - INFO - Going to convert document batch...\n",
      "2025-11-19 22:27:35,293 - INFO - Processing document granite.pdf\n",
      "2025-11-19 22:29:50,682 - INFO - Finished converting document granite.pdf in 135.39 sec.\n",
      "{\"time\": \"22:29:50\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 4 files (50.0%) in 7.675 min\"}\n",
      "2025-11-19 22:29:50,739 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-11-19 22:29:50,740 - INFO - Going to convert document batch...\n",
      "2025-11-19 22:29:50,741 - INFO - Processing document hap1.pdf\n",
      "2025-11-19 22:29:51,553 - INFO - Finished converting document hap1.pdf in 0.81 sec.\n",
      "{\"time\": \"22:29:51\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 5 files (62.5%) in 7.688 min\"}\n",
      "2025-11-19 22:29:51,556 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-11-19 22:29:51,557 - INFO - Going to convert document batch...\n",
      "2025-11-19 22:29:51,558 - INFO - Processing document hap2.pdf\n",
      "2025-11-19 22:29:52,473 - INFO - Finished converting document hap2.pdf in 0.92 sec.\n",
      "{\"time\": \"22:29:52\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 6 files (75.0%) in 7.704 min\"}\n",
      "2025-11-19 22:29:52,477 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-11-19 22:29:52,478 - INFO - Going to convert document batch...\n",
      "2025-11-19 22:29:52,479 - INFO - Processing document lorem-ipsum.pdf\n",
      "2025-11-19 22:29:53,375 - INFO - Finished converting document lorem-ipsum.pdf in 0.90 sec.\n",
      "{\"time\": \"22:29:53\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 7 files (87.5%) in 7.719 min\"}\n",
      "2025-11-19 22:29:53,381 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-11-19 22:29:53,382 - INFO - Going to convert document batch...\n",
      "2025-11-19 22:29:53,383 - INFO - Processing document spam.pdf\n",
      "2025-11-19 22:29:54,284 - INFO - Finished converting document spam.pdf in 0.90 sec.\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 8 files (100.0%) in 7.734 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Done processing 8 files, waiting for flush() completion.\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"done flushing in 0.0 sec\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed execution in 7.776 min, execution result 0\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage:1 completed successfully\n",
      "CPU times: user 40min 28s, sys: 1min 53s, total: 42min 22s\n",
      "Wall time: 7min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from dpk_docling2parquet import Docling2Parquet\n",
    "from dpk_docling2parquet import docling2parquet_contents_types\n",
    "\n",
    "STAGE = 1\n",
    "print (f\"üèÉüèº STAGE-{STAGE}: Processing input='{MY_CONFIG.INPUT_DATA_DIR}' --> output='{output_docling2pq_dir}'\\n\", flush=True)\n",
    "\n",
    "result = Docling2Parquet(input_folder=MY_CONFIG.INPUT_DATA_DIR,\n",
    "                    output_folder=output_docling2pq_dir,\n",
    "                    data_files_to_use=['.pdf'],\n",
    "                    docling2parquet_contents_type=docling2parquet_contents_types.MARKDOWN,   # markdown\n",
    "                    ).transform()\n",
    "\n",
    "if result == 0:\n",
    "    print (f\"‚úÖ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (f\"‚ùå Stage:{STAGE}  failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca790e0",
   "metadata": {},
   "source": [
    "### 3.2 -  Inspect Generated output\n",
    "\n",
    "Here we should see one entry per input file processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe59563d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read 8 parquet files with 8 total rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>contents</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_hash</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "      <th>document_convert_time</th>\n",
       "      <th>source_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>granite-similar.pdf</td>\n",
       "      <td>## Granite Code Models: A Family of Open Found...</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>488</td>\n",
       "      <td>221416c6-c2a2-4aa4-be34-62b47f2b44b8</td>\n",
       "      <td>2995119145186144319</td>\n",
       "      <td>pdf</td>\n",
       "      <td>0de7807974e6888cabafef3484ef571ceb5c3167f7433a...</td>\n",
       "      <td>121236</td>\n",
       "      <td>2025-11-19T22:27:35.280582</td>\n",
       "      <td>144.064493</td>\n",
       "      <td>granite-similar.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lorem-ipsum.pdf</td>\n",
       "      <td>Lorem ipsum Lorem ipsum Lorem ipsum</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1579cb34-5a75-46af-b4c2-f0b80e0fede5</td>\n",
       "      <td>50660627009040522</td>\n",
       "      <td>pdf</td>\n",
       "      <td>bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...</td>\n",
       "      <td>35</td>\n",
       "      <td>2025-11-19T22:29:53.377453</td>\n",
       "      <td>0.899349</td>\n",
       "      <td>lorem-ipsum.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>granite-duplicate.pdf</td>\n",
       "      <td>## Granite Code Models: A Family of Open Found...</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>484</td>\n",
       "      <td>ba897c8f-7637-49e7-9cb4-19e770fd5031</td>\n",
       "      <td>3127757990743433032</td>\n",
       "      <td>pdf</td>\n",
       "      <td>58342470e7d666dca0be87a15fb0552f949a5632606fe1...</td>\n",
       "      <td>121131</td>\n",
       "      <td>2025-11-19T22:25:11.161649</td>\n",
       "      <td>145.223961</td>\n",
       "      <td>granite-duplicate.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam.pdf</td>\n",
       "      <td>Free xxx</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>412bba11-c661-456d-bbbc-bf57de69cbc4</td>\n",
       "      <td>5577338085393325113</td>\n",
       "      <td>pdf</td>\n",
       "      <td>543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...</td>\n",
       "      <td>8</td>\n",
       "      <td>2025-11-19T22:29:54.286406</td>\n",
       "      <td>0.904720</td>\n",
       "      <td>spam.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attention.pdf</td>\n",
       "      <td>Provided proper attribution is provided, Googl...</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>513</td>\n",
       "      <td>b21cf9b2-6c3a-4a22-a5dc-aacecf1a99dc</td>\n",
       "      <td>2949302674760005271</td>\n",
       "      <td>pdf</td>\n",
       "      <td>bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...</td>\n",
       "      <td>48981</td>\n",
       "      <td>2025-11-19T22:22:45.882819</td>\n",
       "      <td>35.593498</td>\n",
       "      <td>attention.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hap2.pdf</td>\n",
       "      <td>## HAP Example - Hate\\n\\nI hate all immigrants!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9a9c972d-86df-470b-acca-51a3135e9074</td>\n",
       "      <td>17586229987672717381</td>\n",
       "      <td>pdf</td>\n",
       "      <td>18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...</td>\n",
       "      <td>45</td>\n",
       "      <td>2025-11-19T22:29:52.475010</td>\n",
       "      <td>0.917891</td>\n",
       "      <td>hap2.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hap1.pdf</td>\n",
       "      <td>## HAP example - Abuse and Profanity\\n\\nYou ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>d4614cde-d599-4da9-969b-1aa9ac57310d</td>\n",
       "      <td>11080891969043035065</td>\n",
       "      <td>pdf</td>\n",
       "      <td>c21aebe6661c25c508faf03d9030813497e4ded4c840f4...</td>\n",
       "      <td>135</td>\n",
       "      <td>2025-11-19T22:29:51.554267</td>\n",
       "      <td>0.814161</td>\n",
       "      <td>hap1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>granite.pdf</td>\n",
       "      <td>## Granite Code Models: A Family of Open Found...</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>484</td>\n",
       "      <td>83d8d8fc-df9a-4476-832d-07fa9f58ca03</td>\n",
       "      <td>3127757990743433032</td>\n",
       "      <td>pdf</td>\n",
       "      <td>58342470e7d666dca0be87a15fb0552f949a5632606fe1...</td>\n",
       "      <td>121131</td>\n",
       "      <td>2025-11-19T22:29:50.727842</td>\n",
       "      <td>135.392525</td>\n",
       "      <td>granite.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename                                           contents  \\\n",
       "0    granite-similar.pdf  ## Granite Code Models: A Family of Open Found...   \n",
       "1        lorem-ipsum.pdf                Lorem ipsum Lorem ipsum Lorem ipsum   \n",
       "2  granite-duplicate.pdf  ## Granite Code Models: A Family of Open Found...   \n",
       "3               spam.pdf                                           Free xxx   \n",
       "4          attention.pdf  Provided proper attribution is provided, Googl...   \n",
       "5               hap2.pdf    ## HAP Example - Hate\\n\\nI hate all immigrants!   \n",
       "6               hap1.pdf  ## HAP example - Abuse and Profanity\\n\\nYou ar...   \n",
       "7            granite.pdf  ## Granite Code Models: A Family of Open Found...   \n",
       "\n",
       "   num_pages  num_tables  num_doc_elements  \\\n",
       "0         28          17               488   \n",
       "1          1           0                 2   \n",
       "2         28          17               484   \n",
       "3          1           0                 2   \n",
       "4         15           4               513   \n",
       "5          1           0                 3   \n",
       "6          1           0                 3   \n",
       "7         28          17               484   \n",
       "\n",
       "                            document_id         document_hash  ext  \\\n",
       "0  221416c6-c2a2-4aa4-be34-62b47f2b44b8   2995119145186144319  pdf   \n",
       "1  1579cb34-5a75-46af-b4c2-f0b80e0fede5     50660627009040522  pdf   \n",
       "2  ba897c8f-7637-49e7-9cb4-19e770fd5031   3127757990743433032  pdf   \n",
       "3  412bba11-c661-456d-bbbc-bf57de69cbc4   5577338085393325113  pdf   \n",
       "4  b21cf9b2-6c3a-4a22-a5dc-aacecf1a99dc   2949302674760005271  pdf   \n",
       "5  9a9c972d-86df-470b-acca-51a3135e9074  17586229987672717381  pdf   \n",
       "6  d4614cde-d599-4da9-969b-1aa9ac57310d  11080891969043035065  pdf   \n",
       "7  83d8d8fc-df9a-4476-832d-07fa9f58ca03   3127757990743433032  pdf   \n",
       "\n",
       "                                                hash    size  \\\n",
       "0  0de7807974e6888cabafef3484ef571ceb5c3167f7433a...  121236   \n",
       "1  bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...      35   \n",
       "2  58342470e7d666dca0be87a15fb0552f949a5632606fe1...  121131   \n",
       "3  543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...       8   \n",
       "4  bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...   48981   \n",
       "5  18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...      45   \n",
       "6  c21aebe6661c25c508faf03d9030813497e4ded4c840f4...     135   \n",
       "7  58342470e7d666dca0be87a15fb0552f949a5632606fe1...  121131   \n",
       "\n",
       "                date_acquired  document_convert_time        source_filename  \n",
       "0  2025-11-19T22:27:35.280582             144.064493    granite-similar.pdf  \n",
       "1  2025-11-19T22:29:53.377453               0.899349        lorem-ipsum.pdf  \n",
       "2  2025-11-19T22:25:11.161649             145.223961  granite-duplicate.pdf  \n",
       "3  2025-11-19T22:29:54.286406               0.904720               spam.pdf  \n",
       "4  2025-11-19T22:22:45.882819              35.593498          attention.pdf  \n",
       "5  2025-11-19T22:29:52.475010               0.917891               hap2.pdf  \n",
       "6  2025-11-19T22:29:51.554267               0.814161               hap1.pdf  \n",
       "7  2025-11-19T22:29:50.727842             135.392525            granite.pdf  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from file_utils import read_parquet_files_as_df\n",
    "\n",
    "output_df = read_parquet_files_as_df(output_docling2pq_dir)\n",
    "\n",
    "# print (\"Output dimensions (rows x columns)= \", output_df.shape)\n",
    "\n",
    "output_df.head(10)\n",
    "\n",
    "## To display certain columns\n",
    "#parquet_df[['column1', 'column2', 'column3']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c32bea7",
   "metadata": {},
   "source": [
    "## Step-4:  Create DOC ID for Documents\n",
    "\n",
    "This transform annotates documents with document \"ids\". It supports the following transformations of the original data:\n",
    "\n",
    " - Adding document hash: this enables the addition of a document hash-based id to the data. The hash is calculated with `hashlib.sha256(doc.encode(\"utf-8\")).hexdigest()`. To enable this annotation, set **hash_column** to the name of the column, where you want to store it.\n",
    " - Adding integer document id: this allows the addition of an integer document id to the data that is unique across all rows in all tables provided to the transform() method. To enable this annotation, set **int_id_column** to the name of the column, where you want to store it.\n",
    "\n",
    "**This step is a pre-requisite for fuzzy dedup** in the pipeline.\n",
    "\n",
    "[DocID documentation](https://github.com/data-prep-kit/data-prep-kit/tree/dev/transforms/universal/doc_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fa778d",
   "metadata": {},
   "source": [
    "### 4.1 - Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b0aac9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉüèº STAGE-2: Processing input='output/1_docling2pq_out' --> output='output/2_docid_out'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Doc id parameters are : {'doc_column': 'contents', 'hash_column': 'doc_hash', 'int_column': 'int_id_column', 'start_id': 0}\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"pipeline id pipeline_id\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"code location {'github': 'UNDEFINED', 'build-date': 'UNDEFINED', 'commit_hash': 'UNDEFINED', 'path': 'UNDEFINED'}\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ max_files -1, n_sample -1\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ Data Access:  DataAccessLocal\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"orchestrator doc_id started at 2025-11-19 22:29:54\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Number of files is 8, source profile {'max_file_size': 0.044300079345703125, 'min_file_size': 0.0055561065673828125, 'total_file_size': 0.17726516723632812}\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 1 files (12.5%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 2 files (25.0%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 3 files (37.5%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 4 files (50.0%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 5 files (62.5%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 6 files (75.0%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 7 files (87.5%) in 0.001 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 8 files (100.0%) in 0.001 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Done processing 8 files, waiting for flush() completion.\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"done flushing in 0.0 sec\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed execution in 0.001 min, execution result 0\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage:2 completed successfully\n",
      "CPU times: user 48.5 ms, sys: 7.21 ms, total: 55.8 ms\n",
      "Wall time: 44.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from dpk_doc_id import DocID\n",
    "\n",
    "STAGE = 2\n",
    "print (f\"üèÉüèº STAGE-{STAGE}: Processing input='{output_docling2pq_dir}' --> output='{output_docid_dir}'\\n\", flush=True)\n",
    "\n",
    "result = DocID(input_folder= output_docling2pq_dir,\n",
    "                output_folder= output_docid_dir,\n",
    "                doc_id_doc_column= \"contents\",\n",
    "                doc_id_hash_column= \"doc_hash\",\n",
    "                # doc_id_int_column= \"doc_id_int\",\n",
    "                doc_id_int_column= \"int_id_column\",\n",
    "                #doc_id_start_id= 5\n",
    "                ).transform()\n",
    "\n",
    "if result == 0:\n",
    "    print (f\"‚úÖ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (f\"‚ùå Stage:{STAGE}  failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969cffa7",
   "metadata": {},
   "source": [
    "### 4.2 - Inspect Generated output\n",
    "\n",
    "You would see a new columns **doc_hash** and **int_id_column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8021b2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying contents of :  output/2_docid_out\n",
      "Successfully read 8 parquet files with 8 total rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>contents</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_hash</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "      <th>document_convert_time</th>\n",
       "      <th>source_filename</th>\n",
       "      <th>doc_hash</th>\n",
       "      <th>int_id_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>granite-similar.pdf</td>\n",
       "      <td>## Granite Code Models: A Family of Open Found...</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>488</td>\n",
       "      <td>221416c6-c2a2-4aa4-be34-62b47f2b44b8</td>\n",
       "      <td>2995119145186144319</td>\n",
       "      <td>pdf</td>\n",
       "      <td>0de7807974e6888cabafef3484ef571ceb5c3167f7433a...</td>\n",
       "      <td>121236</td>\n",
       "      <td>2025-11-19T22:27:35.280582</td>\n",
       "      <td>144.064493</td>\n",
       "      <td>granite-similar.pdf</td>\n",
       "      <td>0de7807974e6888cabafef3484ef571ceb5c3167f7433a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lorem-ipsum.pdf</td>\n",
       "      <td>Lorem ipsum Lorem ipsum Lorem ipsum</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1579cb34-5a75-46af-b4c2-f0b80e0fede5</td>\n",
       "      <td>50660627009040522</td>\n",
       "      <td>pdf</td>\n",
       "      <td>bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...</td>\n",
       "      <td>35</td>\n",
       "      <td>2025-11-19T22:29:53.377453</td>\n",
       "      <td>0.899349</td>\n",
       "      <td>lorem-ipsum.pdf</td>\n",
       "      <td>bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>granite-duplicate.pdf</td>\n",
       "      <td>## Granite Code Models: A Family of Open Found...</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>484</td>\n",
       "      <td>ba897c8f-7637-49e7-9cb4-19e770fd5031</td>\n",
       "      <td>3127757990743433032</td>\n",
       "      <td>pdf</td>\n",
       "      <td>58342470e7d666dca0be87a15fb0552f949a5632606fe1...</td>\n",
       "      <td>121131</td>\n",
       "      <td>2025-11-19T22:25:11.161649</td>\n",
       "      <td>145.223961</td>\n",
       "      <td>granite-duplicate.pdf</td>\n",
       "      <td>58342470e7d666dca0be87a15fb0552f949a5632606fe1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam.pdf</td>\n",
       "      <td>Free xxx</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>412bba11-c661-456d-bbbc-bf57de69cbc4</td>\n",
       "      <td>5577338085393325113</td>\n",
       "      <td>pdf</td>\n",
       "      <td>543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...</td>\n",
       "      <td>8</td>\n",
       "      <td>2025-11-19T22:29:54.286406</td>\n",
       "      <td>0.904720</td>\n",
       "      <td>spam.pdf</td>\n",
       "      <td>543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attention.pdf</td>\n",
       "      <td>Provided proper attribution is provided, Googl...</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>513</td>\n",
       "      <td>b21cf9b2-6c3a-4a22-a5dc-aacecf1a99dc</td>\n",
       "      <td>2949302674760005271</td>\n",
       "      <td>pdf</td>\n",
       "      <td>bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...</td>\n",
       "      <td>48981</td>\n",
       "      <td>2025-11-19T22:22:45.882819</td>\n",
       "      <td>35.593498</td>\n",
       "      <td>attention.pdf</td>\n",
       "      <td>bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hap2.pdf</td>\n",
       "      <td>## HAP Example - Hate\\n\\nI hate all immigrants!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9a9c972d-86df-470b-acca-51a3135e9074</td>\n",
       "      <td>17586229987672717381</td>\n",
       "      <td>pdf</td>\n",
       "      <td>18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...</td>\n",
       "      <td>45</td>\n",
       "      <td>2025-11-19T22:29:52.475010</td>\n",
       "      <td>0.917891</td>\n",
       "      <td>hap2.pdf</td>\n",
       "      <td>18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hap1.pdf</td>\n",
       "      <td>## HAP example - Abuse and Profanity\\n\\nYou ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>d4614cde-d599-4da9-969b-1aa9ac57310d</td>\n",
       "      <td>11080891969043035065</td>\n",
       "      <td>pdf</td>\n",
       "      <td>c21aebe6661c25c508faf03d9030813497e4ded4c840f4...</td>\n",
       "      <td>135</td>\n",
       "      <td>2025-11-19T22:29:51.554267</td>\n",
       "      <td>0.814161</td>\n",
       "      <td>hap1.pdf</td>\n",
       "      <td>c21aebe6661c25c508faf03d9030813497e4ded4c840f4...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>granite.pdf</td>\n",
       "      <td>## Granite Code Models: A Family of Open Found...</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>484</td>\n",
       "      <td>83d8d8fc-df9a-4476-832d-07fa9f58ca03</td>\n",
       "      <td>3127757990743433032</td>\n",
       "      <td>pdf</td>\n",
       "      <td>58342470e7d666dca0be87a15fb0552f949a5632606fe1...</td>\n",
       "      <td>121131</td>\n",
       "      <td>2025-11-19T22:29:50.727842</td>\n",
       "      <td>135.392525</td>\n",
       "      <td>granite.pdf</td>\n",
       "      <td>58342470e7d666dca0be87a15fb0552f949a5632606fe1...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename                                           contents  \\\n",
       "0    granite-similar.pdf  ## Granite Code Models: A Family of Open Found...   \n",
       "1        lorem-ipsum.pdf                Lorem ipsum Lorem ipsum Lorem ipsum   \n",
       "2  granite-duplicate.pdf  ## Granite Code Models: A Family of Open Found...   \n",
       "3               spam.pdf                                           Free xxx   \n",
       "4          attention.pdf  Provided proper attribution is provided, Googl...   \n",
       "5               hap2.pdf    ## HAP Example - Hate\\n\\nI hate all immigrants!   \n",
       "6               hap1.pdf  ## HAP example - Abuse and Profanity\\n\\nYou ar...   \n",
       "7            granite.pdf  ## Granite Code Models: A Family of Open Found...   \n",
       "\n",
       "   num_pages  num_tables  num_doc_elements  \\\n",
       "0         28          17               488   \n",
       "1          1           0                 2   \n",
       "2         28          17               484   \n",
       "3          1           0                 2   \n",
       "4         15           4               513   \n",
       "5          1           0                 3   \n",
       "6          1           0                 3   \n",
       "7         28          17               484   \n",
       "\n",
       "                            document_id         document_hash  ext  \\\n",
       "0  221416c6-c2a2-4aa4-be34-62b47f2b44b8   2995119145186144319  pdf   \n",
       "1  1579cb34-5a75-46af-b4c2-f0b80e0fede5     50660627009040522  pdf   \n",
       "2  ba897c8f-7637-49e7-9cb4-19e770fd5031   3127757990743433032  pdf   \n",
       "3  412bba11-c661-456d-bbbc-bf57de69cbc4   5577338085393325113  pdf   \n",
       "4  b21cf9b2-6c3a-4a22-a5dc-aacecf1a99dc   2949302674760005271  pdf   \n",
       "5  9a9c972d-86df-470b-acca-51a3135e9074  17586229987672717381  pdf   \n",
       "6  d4614cde-d599-4da9-969b-1aa9ac57310d  11080891969043035065  pdf   \n",
       "7  83d8d8fc-df9a-4476-832d-07fa9f58ca03   3127757990743433032  pdf   \n",
       "\n",
       "                                                hash    size  \\\n",
       "0  0de7807974e6888cabafef3484ef571ceb5c3167f7433a...  121236   \n",
       "1  bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...      35   \n",
       "2  58342470e7d666dca0be87a15fb0552f949a5632606fe1...  121131   \n",
       "3  543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...       8   \n",
       "4  bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...   48981   \n",
       "5  18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...      45   \n",
       "6  c21aebe6661c25c508faf03d9030813497e4ded4c840f4...     135   \n",
       "7  58342470e7d666dca0be87a15fb0552f949a5632606fe1...  121131   \n",
       "\n",
       "                date_acquired  document_convert_time        source_filename  \\\n",
       "0  2025-11-19T22:27:35.280582             144.064493    granite-similar.pdf   \n",
       "1  2025-11-19T22:29:53.377453               0.899349        lorem-ipsum.pdf   \n",
       "2  2025-11-19T22:25:11.161649             145.223961  granite-duplicate.pdf   \n",
       "3  2025-11-19T22:29:54.286406               0.904720               spam.pdf   \n",
       "4  2025-11-19T22:22:45.882819              35.593498          attention.pdf   \n",
       "5  2025-11-19T22:29:52.475010               0.917891               hap2.pdf   \n",
       "6  2025-11-19T22:29:51.554267               0.814161               hap1.pdf   \n",
       "7  2025-11-19T22:29:50.727842             135.392525            granite.pdf   \n",
       "\n",
       "                                            doc_hash  int_id_column  \n",
       "0  0de7807974e6888cabafef3484ef571ceb5c3167f7433a...              2  \n",
       "1  bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...              6  \n",
       "2  58342470e7d666dca0be87a15fb0552f949a5632606fe1...              1  \n",
       "3  543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...              7  \n",
       "4  bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...              0  \n",
       "5  18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...              5  \n",
       "6  c21aebe6661c25c508faf03d9030813497e4ded4c840f4...              4  \n",
       "7  58342470e7d666dca0be87a15fb0552f949a5632606fe1...              3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from file_utils import read_parquet_files_as_df\n",
    "print (\"Displaying contents of : \", output_docid_dir)\n",
    "output_df = read_parquet_files_as_df(output_docid_dir)\n",
    "output_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f900753",
   "metadata": {},
   "source": [
    "## Step-5: Eliminate Duplicate Documents\n",
    "\n",
    "We have 2 duplicate documnets here : `granite.pdf` and `granite2.pdf`.\n",
    "\n",
    "Note how the `hash` for these documents are same.\n",
    "\n",
    "We are going to perform **de-dupe**\n",
    "\n",
    "On the content of each document, a SHA256 hash is computed, followed by de-duplication of record having identical hashes.\n",
    "\n",
    "[Dedupe transform documentation](https://github.com/data-prep-kit/data-prep-kit/blob/dev/transforms/universal/ededup/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef93831",
   "metadata": {},
   "source": [
    "### 5.1 - Execute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1901b4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉüèº STAGE-2: Processing input='output/2_docid_out' --> output='output/3_exact_dedupe_out'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"exact dedup params are {'doc_column': 'contents', 'doc_id_column': 'document_id', 'use_snapshot': False, 'snapshot_directory': None}\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"pipeline id pipeline_id\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"code location {'github': 'UNDEFINED', 'build-date': 'UNDEFINED', 'commit_hash': 'UNDEFINED', 'path': 'UNDEFINED'}\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ max_files -1, n_sample -1\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ Data Access:  DataAccessLocal\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"orchestrator ededup started at 2025-11-19 22:29:54\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Number of files is 8, source profile {'max_file_size': 0.04540443420410156, 'min_file_size': 0.006649017333984375, 'total_file_size': 0.1860485076904297}\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Starting from the beginning\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 1 files (12.5%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 2 files (25.0%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 3 files (37.5%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 4 files (50.0%) in 0.001 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 5 files (62.5%) in 0.001 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 6 files (75.0%) in 0.001 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 7 files (87.5%) in 0.001 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 8 files (100.0%) in 0.001 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Done processing 8 files, waiting for flush() completion.\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"done flushing in 0.0 sec\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed execution in 0.001 min, execution result 0\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage:2 completed successfully\n",
      "CPU times: user 59.7 ms, sys: 5.22 ms, total: 64.9 ms\n",
      "Wall time: 55.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "from dpk_ededup.transform_python import Ededup\n",
    "\n",
    "STAGE = 2\n",
    "print (f\"üèÉüèº STAGE-{STAGE}: Processing input='{output_docid_dir}' --> output='{output_exact_dedupe_dir}'\\n\", flush=True)\n",
    "\n",
    "result = Ededup(input_folder=output_docid_dir,\n",
    "    output_folder=output_exact_dedupe_dir,\n",
    "    ededup_doc_column=\"contents\",\n",
    "    ededup_doc_id_column=\"document_id\"\n",
    "    ).transform()\n",
    "\n",
    "if result == 0:\n",
    "    print (f\"‚úÖ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (f\"‚ùå Stage:{STAGE}  failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45a59d2",
   "metadata": {},
   "source": [
    "### 5.2 - Inspect Generated output\n",
    "\n",
    "We would see 2 documents: `attention.pdf`  and `granite.pdf`.  The duplicate `granite.pdf` has been filtered out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0691f08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read 8 parquet files with 8 total rows\n",
      "Successfully read 7 parquet files with 7 total rows\n",
      "Input files before exact dedupe : 8\n",
      "Output files after exact dedupe : 7\n",
      "Duplicate files removed :   1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>contents</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_hash</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "      <th>document_convert_time</th>\n",
       "      <th>source_filename</th>\n",
       "      <th>doc_hash</th>\n",
       "      <th>int_id_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hap1.pdf</td>\n",
       "      <td>## HAP example - Abuse and Profanity\\n\\nYou ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>d4614cde-d599-4da9-969b-1aa9ac57310d</td>\n",
       "      <td>11080891969043035065</td>\n",
       "      <td>pdf</td>\n",
       "      <td>c21aebe6661c25c508faf03d9030813497e4ded4c840f4...</td>\n",
       "      <td>135</td>\n",
       "      <td>2025-11-19T22:29:51.554267</td>\n",
       "      <td>0.814161</td>\n",
       "      <td>hap1.pdf</td>\n",
       "      <td>c21aebe6661c25c508faf03d9030813497e4ded4c840f4...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam.pdf</td>\n",
       "      <td>Free xxx</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>412bba11-c661-456d-bbbc-bf57de69cbc4</td>\n",
       "      <td>5577338085393325113</td>\n",
       "      <td>pdf</td>\n",
       "      <td>543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...</td>\n",
       "      <td>8</td>\n",
       "      <td>2025-11-19T22:29:54.286406</td>\n",
       "      <td>0.904720</td>\n",
       "      <td>spam.pdf</td>\n",
       "      <td>543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>granite-duplicate.pdf</td>\n",
       "      <td>## Granite Code Models: A Family of Open Found...</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>484</td>\n",
       "      <td>ba897c8f-7637-49e7-9cb4-19e770fd5031</td>\n",
       "      <td>3127757990743433032</td>\n",
       "      <td>pdf</td>\n",
       "      <td>58342470e7d666dca0be87a15fb0552f949a5632606fe1...</td>\n",
       "      <td>121131</td>\n",
       "      <td>2025-11-19T22:25:11.161649</td>\n",
       "      <td>145.223961</td>\n",
       "      <td>granite-duplicate.pdf</td>\n",
       "      <td>58342470e7d666dca0be87a15fb0552f949a5632606fe1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hap2.pdf</td>\n",
       "      <td>## HAP Example - Hate\\n\\nI hate all immigrants!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9a9c972d-86df-470b-acca-51a3135e9074</td>\n",
       "      <td>17586229987672717381</td>\n",
       "      <td>pdf</td>\n",
       "      <td>18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...</td>\n",
       "      <td>45</td>\n",
       "      <td>2025-11-19T22:29:52.475010</td>\n",
       "      <td>0.917891</td>\n",
       "      <td>hap2.pdf</td>\n",
       "      <td>18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>granite-similar.pdf</td>\n",
       "      <td>## Granite Code Models: A Family of Open Found...</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>488</td>\n",
       "      <td>221416c6-c2a2-4aa4-be34-62b47f2b44b8</td>\n",
       "      <td>2995119145186144319</td>\n",
       "      <td>pdf</td>\n",
       "      <td>0de7807974e6888cabafef3484ef571ceb5c3167f7433a...</td>\n",
       "      <td>121236</td>\n",
       "      <td>2025-11-19T22:27:35.280582</td>\n",
       "      <td>144.064493</td>\n",
       "      <td>granite-similar.pdf</td>\n",
       "      <td>0de7807974e6888cabafef3484ef571ceb5c3167f7433a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attention.pdf</td>\n",
       "      <td>Provided proper attribution is provided, Googl...</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>513</td>\n",
       "      <td>b21cf9b2-6c3a-4a22-a5dc-aacecf1a99dc</td>\n",
       "      <td>2949302674760005271</td>\n",
       "      <td>pdf</td>\n",
       "      <td>bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...</td>\n",
       "      <td>48981</td>\n",
       "      <td>2025-11-19T22:22:45.882819</td>\n",
       "      <td>35.593498</td>\n",
       "      <td>attention.pdf</td>\n",
       "      <td>bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lorem-ipsum.pdf</td>\n",
       "      <td>Lorem ipsum Lorem ipsum Lorem ipsum</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1579cb34-5a75-46af-b4c2-f0b80e0fede5</td>\n",
       "      <td>50660627009040522</td>\n",
       "      <td>pdf</td>\n",
       "      <td>bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...</td>\n",
       "      <td>35</td>\n",
       "      <td>2025-11-19T22:29:53.377453</td>\n",
       "      <td>0.899349</td>\n",
       "      <td>lorem-ipsum.pdf</td>\n",
       "      <td>bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename                                           contents  \\\n",
       "6               hap1.pdf  ## HAP example - Abuse and Profanity\\n\\nYou ar...   \n",
       "3               spam.pdf                                           Free xxx   \n",
       "2  granite-duplicate.pdf  ## Granite Code Models: A Family of Open Found...   \n",
       "5               hap2.pdf    ## HAP Example - Hate\\n\\nI hate all immigrants!   \n",
       "0    granite-similar.pdf  ## Granite Code Models: A Family of Open Found...   \n",
       "4          attention.pdf  Provided proper attribution is provided, Googl...   \n",
       "1        lorem-ipsum.pdf                Lorem ipsum Lorem ipsum Lorem ipsum   \n",
       "\n",
       "   num_pages  num_tables  num_doc_elements  \\\n",
       "6          1           0                 3   \n",
       "3          1           0                 2   \n",
       "2         28          17               484   \n",
       "5          1           0                 3   \n",
       "0         28          17               488   \n",
       "4         15           4               513   \n",
       "1          1           0                 2   \n",
       "\n",
       "                            document_id         document_hash  ext  \\\n",
       "6  d4614cde-d599-4da9-969b-1aa9ac57310d  11080891969043035065  pdf   \n",
       "3  412bba11-c661-456d-bbbc-bf57de69cbc4   5577338085393325113  pdf   \n",
       "2  ba897c8f-7637-49e7-9cb4-19e770fd5031   3127757990743433032  pdf   \n",
       "5  9a9c972d-86df-470b-acca-51a3135e9074  17586229987672717381  pdf   \n",
       "0  221416c6-c2a2-4aa4-be34-62b47f2b44b8   2995119145186144319  pdf   \n",
       "4  b21cf9b2-6c3a-4a22-a5dc-aacecf1a99dc   2949302674760005271  pdf   \n",
       "1  1579cb34-5a75-46af-b4c2-f0b80e0fede5     50660627009040522  pdf   \n",
       "\n",
       "                                                hash    size  \\\n",
       "6  c21aebe6661c25c508faf03d9030813497e4ded4c840f4...     135   \n",
       "3  543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...       8   \n",
       "2  58342470e7d666dca0be87a15fb0552f949a5632606fe1...  121131   \n",
       "5  18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...      45   \n",
       "0  0de7807974e6888cabafef3484ef571ceb5c3167f7433a...  121236   \n",
       "4  bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...   48981   \n",
       "1  bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...      35   \n",
       "\n",
       "                date_acquired  document_convert_time        source_filename  \\\n",
       "6  2025-11-19T22:29:51.554267               0.814161               hap1.pdf   \n",
       "3  2025-11-19T22:29:54.286406               0.904720               spam.pdf   \n",
       "2  2025-11-19T22:25:11.161649             145.223961  granite-duplicate.pdf   \n",
       "5  2025-11-19T22:29:52.475010               0.917891               hap2.pdf   \n",
       "0  2025-11-19T22:27:35.280582             144.064493    granite-similar.pdf   \n",
       "4  2025-11-19T22:22:45.882819              35.593498          attention.pdf   \n",
       "1  2025-11-19T22:29:53.377453               0.899349        lorem-ipsum.pdf   \n",
       "\n",
       "                                            doc_hash  int_id_column  \n",
       "6  c21aebe6661c25c508faf03d9030813497e4ded4c840f4...              4  \n",
       "3  543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...              7  \n",
       "2  58342470e7d666dca0be87a15fb0552f949a5632606fe1...              1  \n",
       "5  18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...              5  \n",
       "0  0de7807974e6888cabafef3484ef571ceb5c3167f7433a...              2  \n",
       "4  bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...              0  \n",
       "1  bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...              6  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from file_utils import read_parquet_files_as_df\n",
    "\n",
    "input_df = read_parquet_files_as_df(output_docid_dir)\n",
    "output_df = read_parquet_files_as_df(output_exact_dedupe_dir)\n",
    "\n",
    "# print (\"Input data dimensions (rows x columns)= \", input_df.shape)\n",
    "# print (\"Output data dimensions (rows x columns)= \", output_df.shape)\n",
    "print (f\"Input files before exact dedupe : {input_df.shape[0]:,}\")\n",
    "print (f\"Output files after exact dedupe : {output_df.shape[0]:,}\")\n",
    "print (\"Duplicate files removed :  \", (input_df.shape[0] - output_df.shape[0]))\n",
    "\n",
    "output_df.sample(min(10, output_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08492be1",
   "metadata": {},
   "source": [
    "## Step-6: Fuzzy Dedupe\n",
    "\n",
    "In previous step, we removed **exact duplicates (identical documents)**.\n",
    "\n",
    "Fuzzy de-dupe can further filter out documents that are **not exactly identical, but nearly identical**\n",
    "\n",
    "Here is a simple example:\n",
    "\n",
    "`Our solar system is a vast and fascinating expanse`\n",
    "\n",
    "`The solar system is a vast and fascinating expanse`\n",
    "\n",
    "Only one word is different `Our` vs `The`.\n",
    "\n",
    "Imagine two documents with one extra blank line.  For our purposes they are the same.\n",
    "\n",
    "[Fuzzy dedupe documentation](https://github.com/data-prep-kit/data-prep-kit/tree/dev/transforms/universal/fdedup)\n",
    "\n",
    "### Tweaking fuzzy matches\n",
    "\n",
    "**`jaccard_similarity_threshold`** is the parameter used to tweak similarities between documents.  It's value is between 0 and 1.0.  Values close to 1.0 means more strict checking (fewer documents will qualify).  Lower threshold means more leniant matches (more documents will qualify)\n",
    "\n",
    "Adjust this value to find what works for your documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67032da6",
   "metadata": {},
   "source": [
    "### 6.1 - Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0d8ec93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉüèº STAGE-4: Processing input='output/3_exact_dedupe_out' --> output='output/4_fuzzy_dedupe_out'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Starting SignatureCalculation step\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Got parameters for SignatureCalculation\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"minhash parameters are : {'document_id_column': 'int_id_column', 'contents_column': 'contents', 'seed': 42, 'num_permutations': 112, 'jaccard_similarity_threshold': 0.8, 'word_shingle_size': 5, 'num_bands': 14, 'num_minhashes_per_band': 8, 'num_segments': 1, 'shingle_option': 'word'}\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory scdata_ Missing local configuration\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory scdata_ max_files -1, n_sample -1\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory scdata_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory scdata_ Data Access:  DataAccessLocal\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data access factory scdata_: No config provided\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"pipeline id pipeline_id\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"code location {'github': 'UNDEFINED', 'build-date': 'UNDEFINED', 'commit_hash': 'UNDEFINED', 'path': 'UNDEFINED'}\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ max_files -1, n_sample -1\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ Data Access:  DataAccessLocal\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"orchestrator minhash started at 2025-11-19 22:29:54\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Number of files is 8, source profile {'max_file_size': 0.04540443420410156, 'min_file_size': 0.0032377243041992188, 'total_file_size': 0.14401531219482422}\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 1 files (12.5%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 2 files (25.0%) in 0.001 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 3 files (37.5%) in 0.001 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"WARNING\", \"message\": \"table is empty, skipping processing\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 4 files (50.0%) in 0.001 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 5 files (62.5%) in 0.001 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 6 files (75.0%) in 0.001 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 7 files (87.5%) in 0.002 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 8 files (100.0%) in 0.002 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Done processing 8 files, waiting for flush() completion.\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Starting flush()\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Wrote 14 tables with a total size of 47,040 bytes\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"done flushing in 0.039 sec\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed execution in 0.002 min, execution result 0\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"SignatureCalculation completed successfully\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Starting ClusterAnalysis step\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Got parameters for ClusterAnalysis\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"cluster parameters are : {'jaccard_similarity_threshold': 0.8, 'num_bands': 14, 'num_segments': 1, 'sort_output': False}\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"pipeline id pipeline_id\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"code location {'github': 'UNDEFINED', 'build-date': 'UNDEFINED', 'commit_hash': 'UNDEFINED', 'path': 'UNDEFINED'}\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ max_files -1, n_sample -1\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ Data Access:  DataAccessLocal\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"orchestrator cluster started at 2025-11-19 22:29:54\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Number of folders is 14\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 1 files (7.14%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 2 files (14.29%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 3 files (21.43%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 4 files (28.57%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 5 files (35.71%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 6 files (42.86%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 7 files (50.0%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 8 files (57.14%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 9 files (64.29%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 10 files (71.43%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 11 files (78.57%) in 0.001 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 12 files (85.71%) in 0.001 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 13 files (92.86%) in 0.001 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 14 files (100.0%) in 0.001 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Done processing 14 files, waiting for flush() completion.\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"done flushing in 0.0 sec\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed execution in 0.001 min, execution result 0\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"ClusterAnalysis completed successfully\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Starting GetDuplicateList step\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Got parameters for GetDuplicateList\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"fdlist parameters are : {'docs_to_remove': 'docs_to_remove', 'consolidated_filename': 'docs_to_remove_consolidated/docs_to_remove_consolidated.parquet', 'sort_output': False}\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"pipeline id pipeline_id\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"code location {'github': 'UNDEFINED', 'build-date': 'UNDEFINED', 'commit_hash': 'UNDEFINED', 'path': 'UNDEFINED'}\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ max_files -1, n_sample -1\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ Data Access:  DataAccessLocal\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"orchestrator fdlist started at 2025-11-19 22:29:54\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Number of folders is 1\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Get Duplicate List for folder docs_to_remove\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"1 documents marked as duplicates\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 1 files (100.0%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Done processing 1 files, waiting for flush() completion.\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"done flushing in 0.0 sec\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed execution in 0.0 min, execution result 0\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"GetDuplicateList completed successfully\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Starting DataCleaning step\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Got parameters for DataCleaning\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"fdclean parameters are : {'document_id_column': 'int_id_column', 'duplicate_list_location': 'docs_to_remove_consolidated/docs_to_remove_consolidated.parquet', 'operation_mode': 'filter_duplicates'}\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory dcdata_ Missing local configuration\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory dcdata_ max_files -1, n_sample -1\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory dcdata_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory dcdata_ Data Access:  DataAccessLocal\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data access factory dcdata_: No config provided\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"pipeline id pipeline_id\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"code location {'github': 'UNDEFINED', 'build-date': 'UNDEFINED', 'commit_hash': 'UNDEFINED', 'path': 'UNDEFINED'}\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ max_files -1, n_sample -1\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ Data Access:  DataAccessLocal\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"orchestrator fdclean started at 2025-11-19 22:29:54\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Number of files is 8, source profile {'max_file_size': 0.04540443420410156, 'min_file_size': 0.0032377243041992188, 'total_file_size': 0.14401531219482422}\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 1 files (12.5%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 2 files (25.0%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 3 files (37.5%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"WARNING\", \"message\": \"table is empty, skipping processing\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 4 files (50.0%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 5 files (62.5%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 6 files (75.0%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 7 files (87.5%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 8 files (100.0%) in 0.0 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Done processing 8 files, waiting for flush() completion.\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"done flushing in 0.0 sec\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed execution in 0.0 min, execution result 0\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"DataCleaning completed successfully\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage:4 completed successfully\n",
      "CPU times: user 352 ms, sys: 92 ms, total: 444 ms\n",
      "Wall time: 276 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from dpk_fdedup.transform_python import Fdedup\n",
    "\n",
    "STAGE = 4\n",
    "print (f\"üèÉüèº STAGE-{STAGE}: Processing input='{output_exact_dedupe_dir}' --> output='{output_fuzzy_dedupe_dir}'\\n\", flush=True)\n",
    "\n",
    "result = Fdedup(input_folder=output_exact_dedupe_dir,\n",
    "                output_folder=output_fuzzy_dedupe_dir,\n",
    "                contents_column= \"contents\",\n",
    "                # document_id_column= \"doc_id\",\n",
    "                document_id_column= \"int_id_column\",\n",
    "                num_permutations= 112,\n",
    "                num_bands= 14,\n",
    "                num_minhashes_per_band= 8,\n",
    "                jaccard_similarity_threshold = 0.8, # between 0 - 1.  higher means more strict checking\n",
    "                operation_mode=\"filter_duplicates\",\n",
    "                # operation_mode=\"annotate\",\n",
    "                ).transform()\n",
    "if result == 0:\n",
    "    print (f\"‚úÖ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (f\"‚ùå Stage:{STAGE}  failed (result={result})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83513c53",
   "metadata": {},
   "source": [
    "### 6.2 - Inspect Output\n",
    "\n",
    "FuzzyDedupe will write documents that are filtered in **output/4_fuzzy_dedupe_out/cleaned** folder\n",
    "\n",
    "You will notice only one **granite.pdf** made it!  So fuzzy dedupe did filter out the almost identical doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ad5a3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read 7 parquet files with 7 total rows\n",
      "Successfully read 6 parquet files with 6 total rows\n",
      "Input files before exact dedupe : 7\n",
      "Output files after exact dedupe : 6\n",
      "Near duplicate files removed :   1\n",
      "Displaying contents of :  output/4_fuzzy_dedupe_out\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>contents</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_hash</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "      <th>document_convert_time</th>\n",
       "      <th>source_filename</th>\n",
       "      <th>doc_hash</th>\n",
       "      <th>int_id_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>granite-similar.pdf</td>\n",
       "      <td>## Granite Code Models: A Family of Open Found...</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>488</td>\n",
       "      <td>221416c6-c2a2-4aa4-be34-62b47f2b44b8</td>\n",
       "      <td>2995119145186144319</td>\n",
       "      <td>pdf</td>\n",
       "      <td>0de7807974e6888cabafef3484ef571ceb5c3167f7433a...</td>\n",
       "      <td>121236</td>\n",
       "      <td>2025-11-19T22:27:35.280582</td>\n",
       "      <td>144.064493</td>\n",
       "      <td>granite-similar.pdf</td>\n",
       "      <td>0de7807974e6888cabafef3484ef571ceb5c3167f7433a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lorem-ipsum.pdf</td>\n",
       "      <td>Lorem ipsum Lorem ipsum Lorem ipsum</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1579cb34-5a75-46af-b4c2-f0b80e0fede5</td>\n",
       "      <td>50660627009040522</td>\n",
       "      <td>pdf</td>\n",
       "      <td>bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...</td>\n",
       "      <td>35</td>\n",
       "      <td>2025-11-19T22:29:53.377453</td>\n",
       "      <td>0.899349</td>\n",
       "      <td>lorem-ipsum.pdf</td>\n",
       "      <td>bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam.pdf</td>\n",
       "      <td>Free xxx</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>412bba11-c661-456d-bbbc-bf57de69cbc4</td>\n",
       "      <td>5577338085393325113</td>\n",
       "      <td>pdf</td>\n",
       "      <td>543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...</td>\n",
       "      <td>8</td>\n",
       "      <td>2025-11-19T22:29:54.286406</td>\n",
       "      <td>0.904720</td>\n",
       "      <td>spam.pdf</td>\n",
       "      <td>543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention.pdf</td>\n",
       "      <td>Provided proper attribution is provided, Googl...</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>513</td>\n",
       "      <td>b21cf9b2-6c3a-4a22-a5dc-aacecf1a99dc</td>\n",
       "      <td>2949302674760005271</td>\n",
       "      <td>pdf</td>\n",
       "      <td>bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...</td>\n",
       "      <td>48981</td>\n",
       "      <td>2025-11-19T22:22:45.882819</td>\n",
       "      <td>35.593498</td>\n",
       "      <td>attention.pdf</td>\n",
       "      <td>bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hap2.pdf</td>\n",
       "      <td>## HAP Example - Hate\\n\\nI hate all immigrants!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9a9c972d-86df-470b-acca-51a3135e9074</td>\n",
       "      <td>17586229987672717381</td>\n",
       "      <td>pdf</td>\n",
       "      <td>18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...</td>\n",
       "      <td>45</td>\n",
       "      <td>2025-11-19T22:29:52.475010</td>\n",
       "      <td>0.917891</td>\n",
       "      <td>hap2.pdf</td>\n",
       "      <td>18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hap1.pdf</td>\n",
       "      <td>## HAP example - Abuse and Profanity\\n\\nYou ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>d4614cde-d599-4da9-969b-1aa9ac57310d</td>\n",
       "      <td>11080891969043035065</td>\n",
       "      <td>pdf</td>\n",
       "      <td>c21aebe6661c25c508faf03d9030813497e4ded4c840f4...</td>\n",
       "      <td>135</td>\n",
       "      <td>2025-11-19T22:29:51.554267</td>\n",
       "      <td>0.814161</td>\n",
       "      <td>hap1.pdf</td>\n",
       "      <td>c21aebe6661c25c508faf03d9030813497e4ded4c840f4...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename                                           contents  \\\n",
       "0  granite-similar.pdf  ## Granite Code Models: A Family of Open Found...   \n",
       "1      lorem-ipsum.pdf                Lorem ipsum Lorem ipsum Lorem ipsum   \n",
       "2             spam.pdf                                           Free xxx   \n",
       "3        attention.pdf  Provided proper attribution is provided, Googl...   \n",
       "4             hap2.pdf    ## HAP Example - Hate\\n\\nI hate all immigrants!   \n",
       "5             hap1.pdf  ## HAP example - Abuse and Profanity\\n\\nYou ar...   \n",
       "\n",
       "   num_pages  num_tables  num_doc_elements  \\\n",
       "0         28          17               488   \n",
       "1          1           0                 2   \n",
       "2          1           0                 2   \n",
       "3         15           4               513   \n",
       "4          1           0                 3   \n",
       "5          1           0                 3   \n",
       "\n",
       "                            document_id         document_hash  ext  \\\n",
       "0  221416c6-c2a2-4aa4-be34-62b47f2b44b8   2995119145186144319  pdf   \n",
       "1  1579cb34-5a75-46af-b4c2-f0b80e0fede5     50660627009040522  pdf   \n",
       "2  412bba11-c661-456d-bbbc-bf57de69cbc4   5577338085393325113  pdf   \n",
       "3  b21cf9b2-6c3a-4a22-a5dc-aacecf1a99dc   2949302674760005271  pdf   \n",
       "4  9a9c972d-86df-470b-acca-51a3135e9074  17586229987672717381  pdf   \n",
       "5  d4614cde-d599-4da9-969b-1aa9ac57310d  11080891969043035065  pdf   \n",
       "\n",
       "                                                hash    size  \\\n",
       "0  0de7807974e6888cabafef3484ef571ceb5c3167f7433a...  121236   \n",
       "1  bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...      35   \n",
       "2  543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...       8   \n",
       "3  bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...   48981   \n",
       "4  18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...      45   \n",
       "5  c21aebe6661c25c508faf03d9030813497e4ded4c840f4...     135   \n",
       "\n",
       "                date_acquired  document_convert_time      source_filename  \\\n",
       "0  2025-11-19T22:27:35.280582             144.064493  granite-similar.pdf   \n",
       "1  2025-11-19T22:29:53.377453               0.899349      lorem-ipsum.pdf   \n",
       "2  2025-11-19T22:29:54.286406               0.904720             spam.pdf   \n",
       "3  2025-11-19T22:22:45.882819              35.593498        attention.pdf   \n",
       "4  2025-11-19T22:29:52.475010               0.917891             hap2.pdf   \n",
       "5  2025-11-19T22:29:51.554267               0.814161             hap1.pdf   \n",
       "\n",
       "                                            doc_hash  int_id_column  \n",
       "0  0de7807974e6888cabafef3484ef571ceb5c3167f7433a...              2  \n",
       "1  bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...              6  \n",
       "2  543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...              7  \n",
       "3  bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...              0  \n",
       "4  18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...              5  \n",
       "5  c21aebe6661c25c508faf03d9030813497e4ded4c840f4...              4  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from file_utils import read_parquet_files_as_df\n",
    "input_df = read_parquet_files_as_df(output_exact_dedupe_dir)\n",
    "output_df = read_parquet_files_as_df(os.path.join(output_fuzzy_dedupe_dir, \"cleaned\"))\n",
    "\n",
    "# print (\"Input data dimensions (rows x columns)= \", input_df.shape)\n",
    "# print (\"Output data dimensions (rows x columns)= \", output_df.shape)\n",
    "print (f\"Input files before exact dedupe : {input_df.shape[0]:,}\")\n",
    "print (f\"Output files after exact dedupe : {output_df.shape[0]:,}\")\n",
    "print (\"Near duplicate files removed :  \", (input_df.shape[0] - output_df.shape[0]))\n",
    "\n",
    "print (\"Displaying contents of : \", output_fuzzy_dedupe_dir)\n",
    "output_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a80e0df",
   "metadata": {},
   "source": [
    "## Step-7: Document Quality\n",
    "\n",
    "This handy plugin will score documents across many metrics.\n",
    "\n",
    "Here we will look for 'bad words' metric.\n",
    "\n",
    "[Document quality documentation](https://github.com/data-prep-kit/data-prep-kit/tree/dev/transforms/language/doc_quality)\n",
    "\n",
    "By default it uses [bad words collection](https://github.com/data-prep-kit/data-prep-kit/tree/dev/transforms/language/doc_quality/dpk_doc_quality/ldnoobw).  You can supply a custom file by passing an argument `bad_word_filepath=/path/to/badwords_file`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53537b7",
   "metadata": {},
   "source": [
    "### 7.1 - Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de3be423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉüèº STAGE-5: Processing input='output/4_fuzzy_dedupe_out/cleaned' --> output='output/5_doc_quality_out'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"doc_quality parameters are : {'text_lang': 'en', 'doc_content_column': 'contents', 'bad_word_filepath': '/home/sujee/my-stuff/ai-alliance/data-prep-kit-examples/dpk-dev/.venv/lib/python3.12/site-packages/dpk_doc_quality/ldnoobw/en', 'docq_data_factory': <data_processing.data_access.data_access_factory.DataAccessFactory object at 0x7dfaee840260>}\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory docq_ Missing local configuration\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory docq_ max_files -1, n_sample -1\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory docq_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory docq_ Data Access:  DataAccessLocal\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"pipeline id pipeline_id\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"code location {'github': 'UNDEFINED', 'build-date': 'UNDEFINED', 'commit_hash': 'UNDEFINED', 'path': 'UNDEFINED'}\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ max_files -1, n_sample -1\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ Data Access:  DataAccessLocal\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"orchestrator docq started at 2025-11-19 22:29:54\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Number of files is 7, source profile {'max_file_size': 0.04538154602050781, 'min_file_size': 0.0032377243041992188, 'total_file_size': 0.09861087799072266}\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Load badwords found locally from /home/sujee/my-stuff/ai-alliance/data-prep-kit-examples/dpk-dev/.venv/lib/python3.12/site-packages/dpk_doc_quality/ldnoobw/en\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 1 files (14.29%) in 0.001 min\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"WARNING\", \"message\": \"table is empty, skipping processing\"}\n",
      "{\"time\": \"22:29:54\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 2 files (28.57%) in 0.001 min\"}\n",
      "{\"time\": \"22:29:55\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 3 files (42.86%) in 0.003 min\"}\n",
      "{\"time\": \"22:29:55\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 4 files (57.14%) in 0.003 min\"}\n",
      "{\"time\": \"22:29:55\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 5 files (71.43%) in 0.003 min\"}\n",
      "{\"time\": \"22:29:55\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 6 files (85.71%) in 0.003 min\"}\n",
      "{\"time\": \"22:29:55\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 7 files (100.0%) in 0.003 min\"}\n",
      "{\"time\": \"22:29:55\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Done processing 7 files, waiting for flush() completion.\"}\n",
      "{\"time\": \"22:29:55\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"done flushing in 0.0 sec\"}\n",
      "{\"time\": \"22:29:55\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed execution in 0.003 min, execution result 0\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stage:5 completed successfully\n",
      "CPU times: user 217 ms, sys: 18.7 ms, total: 236 ms\n",
      "Wall time: 224 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from dpk_doc_quality.transform_python import DocQuality\n",
    "\n",
    "STAGE = 5\n",
    "output_fuzzy_dedupe_cleaned_dir = os.path.join(output_fuzzy_dedupe_dir, \"cleaned\")\n",
    "print (f\"üèÉüèº STAGE-{STAGE}: Processing input='{output_fuzzy_dedupe_cleaned_dir}' --> output='{output_doc_quality_dir}'\\n\", flush=True)\n",
    "\n",
    "result = DocQuality(input_folder=output_fuzzy_dedupe_cleaned_dir,\n",
    "                    output_folder= output_doc_quality_dir,\n",
    "                    docq_text_lang = \"en\",\n",
    "                    docq_doc_content_column =\"contents\",\n",
    "                    ).transform()\n",
    "\n",
    "if result == 0:\n",
    "    print (f\"‚úÖ Stage:{STAGE} completed successfully\")\n",
    "else:\n",
    "    raise Exception (f\"‚ùå Stage:{STAGE}  failed (result={result})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c7ee52",
   "metadata": {},
   "source": [
    "### 7.2 - Inspect the Output\n",
    "\n",
    "We will see several new columns starting with the name **docq_**.\n",
    "\n",
    "Look at the column **docq_contain_bad_word**; this will flag documents with 'bad words'.\n",
    "\n",
    "Also inspect the column **docq_lorem_ipsum_ratio**; this will flag documents with 'lorem ipsum' text\n",
    "\n",
    "For more information see : [Doc Quality documentation](https://github.com/data-prep-kit/data-prep-kit/tree/dev/transforms/language/doc_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b47aa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read 6 parquet files with 6 total rows\n",
      "Displaying contents of :  output/5_doc_quality_out\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>contents</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_hash</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>...</th>\n",
       "      <th>docq_mean_word_len</th>\n",
       "      <th>docq_symbol_to_word_ratio</th>\n",
       "      <th>docq_sentence_count</th>\n",
       "      <th>docq_lorem_ipsum_ratio</th>\n",
       "      <th>docq_curly_bracket_ratio</th>\n",
       "      <th>docq_contain_bad_word</th>\n",
       "      <th>docq_bullet_point_ratio</th>\n",
       "      <th>docq_ellipsis_line_ratio</th>\n",
       "      <th>docq_alphabet_word_ratio</th>\n",
       "      <th>docq_contain_common_en_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>granite-similar.pdf</td>\n",
       "      <td>## Granite Code Models: A Family of Open Found...</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>488</td>\n",
       "      <td>221416c6-c2a2-4aa4-be34-62b47f2b44b8</td>\n",
       "      <td>2995119145186144319</td>\n",
       "      <td>pdf</td>\n",
       "      <td>0de7807974e6888cabafef3484ef571ceb5c3167f7433a...</td>\n",
       "      <td>121236</td>\n",
       "      <td>...</td>\n",
       "      <td>5.177224</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>2809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.110682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.663245</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lorem-ipsum.pdf</td>\n",
       "      <td>Lorem ipsum Lorem ipsum Lorem ipsum</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1579cb34-5a75-46af-b4c2-f0b80e0fede5</td>\n",
       "      <td>50660627009040522</td>\n",
       "      <td>pdf</td>\n",
       "      <td>bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam.pdf</td>\n",
       "      <td>Free xxx</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>412bba11-c661-456d-bbbc-bf57de69cbc4</td>\n",
       "      <td>5577338085393325113</td>\n",
       "      <td>pdf</td>\n",
       "      <td>543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention.pdf</td>\n",
       "      <td>Provided proper attribution is provided, Googl...</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>513</td>\n",
       "      <td>b21cf9b2-6c3a-4a22-a5dc-aacecf1a99dc</td>\n",
       "      <td>2949302674760005271</td>\n",
       "      <td>pdf</td>\n",
       "      <td>bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...</td>\n",
       "      <td>48981</td>\n",
       "      <td>...</td>\n",
       "      <td>5.058187</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>541</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.117808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.799880</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hap2.pdf</td>\n",
       "      <td>## HAP Example - Hate\\n\\nI hate all immigrants!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9a9c972d-86df-470b-acca-51a3135e9074</td>\n",
       "      <td>17586229987672717381</td>\n",
       "      <td>pdf</td>\n",
       "      <td>18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hap1.pdf</td>\n",
       "      <td>## HAP example - Abuse and Profanity\\n\\nYou ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>d4614cde-d599-4da9-969b-1aa9ac57310d</td>\n",
       "      <td>11080891969043035065</td>\n",
       "      <td>pdf</td>\n",
       "      <td>c21aebe6661c25c508faf03d9030813497e4ded4c840f4...</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename                                           contents  \\\n",
       "0  granite-similar.pdf  ## Granite Code Models: A Family of Open Found...   \n",
       "1      lorem-ipsum.pdf                Lorem ipsum Lorem ipsum Lorem ipsum   \n",
       "2             spam.pdf                                           Free xxx   \n",
       "3        attention.pdf  Provided proper attribution is provided, Googl...   \n",
       "4             hap2.pdf    ## HAP Example - Hate\\n\\nI hate all immigrants!   \n",
       "5             hap1.pdf  ## HAP example - Abuse and Profanity\\n\\nYou ar...   \n",
       "\n",
       "   num_pages  num_tables  num_doc_elements  \\\n",
       "0         28          17               488   \n",
       "1          1           0                 2   \n",
       "2          1           0                 2   \n",
       "3         15           4               513   \n",
       "4          1           0                 3   \n",
       "5          1           0                 3   \n",
       "\n",
       "                            document_id         document_hash  ext  \\\n",
       "0  221416c6-c2a2-4aa4-be34-62b47f2b44b8   2995119145186144319  pdf   \n",
       "1  1579cb34-5a75-46af-b4c2-f0b80e0fede5     50660627009040522  pdf   \n",
       "2  412bba11-c661-456d-bbbc-bf57de69cbc4   5577338085393325113  pdf   \n",
       "3  b21cf9b2-6c3a-4a22-a5dc-aacecf1a99dc   2949302674760005271  pdf   \n",
       "4  9a9c972d-86df-470b-acca-51a3135e9074  17586229987672717381  pdf   \n",
       "5  d4614cde-d599-4da9-969b-1aa9ac57310d  11080891969043035065  pdf   \n",
       "\n",
       "                                                hash    size  ...  \\\n",
       "0  0de7807974e6888cabafef3484ef571ceb5c3167f7433a...  121236  ...   \n",
       "1  bc012d063005cc02deb6c2592d1f8c3b273625edf9eec5...      35  ...   \n",
       "2  543ffc97aef373ee009a5f908e0358ef80d329ca7ba964...       8  ...   \n",
       "3  bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...   48981  ...   \n",
       "4  18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...      45  ...   \n",
       "5  c21aebe6661c25c508faf03d9030813497e4ded4c840f4...     135  ...   \n",
       "\n",
       "  docq_mean_word_len  docq_symbol_to_word_ratio docq_sentence_count  \\\n",
       "0           5.177224                   0.002295                2809   \n",
       "1           5.000000                   0.000000                   1   \n",
       "2           3.500000                   0.000000                   1   \n",
       "3           5.058187                   0.004962                 541   \n",
       "4           4.000000                   0.111111                   1   \n",
       "5           4.625000                   0.041667                   2   \n",
       "\n",
       "  docq_lorem_ipsum_ratio  docq_curly_bracket_ratio  docq_contain_bad_word  \\\n",
       "0               0.000000                       0.0                  False   \n",
       "1               0.085714                       0.0                  False   \n",
       "2               0.000000                       0.0                   True   \n",
       "3               0.000000                       0.0                  False   \n",
       "4               0.000000                       0.0                  False   \n",
       "5               0.000000                       0.0                  False   \n",
       "\n",
       "   docq_bullet_point_ratio  docq_ellipsis_line_ratio  \\\n",
       "0                 0.110682                       0.0   \n",
       "1                 0.000000                       0.0   \n",
       "2                 0.000000                       0.0   \n",
       "3                 0.117808                       0.0   \n",
       "4                 0.000000                       0.0   \n",
       "5                 0.000000                       0.0   \n",
       "\n",
       "   docq_alphabet_word_ratio  docq_contain_common_en_words  \n",
       "0                  0.663245                          True  \n",
       "1                  1.000000                         False  \n",
       "2                  1.000000                         False  \n",
       "3                  0.799880                          True  \n",
       "4                  0.777778                         False  \n",
       "5                  0.916667                          True  \n",
       "\n",
       "[6 rows x 26 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from file_utils import read_parquet_files_as_df\n",
    "output_df = read_parquet_files_as_df(output_doc_quality_dir)\n",
    "print (\"Displaying contents of : \", output_doc_quality_dir)\n",
    "output_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7562e7",
   "metadata": {},
   "source": [
    "### 7.3 - Filtering 'quality' documents\n",
    "\n",
    "So from the output above we see **spam.pdf** is flagged for containing bad words (**docq_contain_bad_word=True**).\n",
    "\n",
    "Also **lorem.pdf** is flagged for place holder content **lorem ipsum**  (**docq_lorem_ipsum_ratio > 0**)\n",
    "\n",
    "We are going to filter them both out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c527fb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read 6 parquet files with 6 total rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>contents</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_hash</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>...</th>\n",
       "      <th>docq_mean_word_len</th>\n",
       "      <th>docq_symbol_to_word_ratio</th>\n",
       "      <th>docq_sentence_count</th>\n",
       "      <th>docq_lorem_ipsum_ratio</th>\n",
       "      <th>docq_curly_bracket_ratio</th>\n",
       "      <th>docq_contain_bad_word</th>\n",
       "      <th>docq_bullet_point_ratio</th>\n",
       "      <th>docq_ellipsis_line_ratio</th>\n",
       "      <th>docq_alphabet_word_ratio</th>\n",
       "      <th>docq_contain_common_en_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>granite-similar.pdf</td>\n",
       "      <td>## Granite Code Models: A Family of Open Found...</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>488</td>\n",
       "      <td>221416c6-c2a2-4aa4-be34-62b47f2b44b8</td>\n",
       "      <td>2995119145186144319</td>\n",
       "      <td>pdf</td>\n",
       "      <td>0de7807974e6888cabafef3484ef571ceb5c3167f7433a...</td>\n",
       "      <td>121236</td>\n",
       "      <td>...</td>\n",
       "      <td>5.177224</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>2809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.110682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.663245</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>attention.pdf</td>\n",
       "      <td>Provided proper attribution is provided, Googl...</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>513</td>\n",
       "      <td>b21cf9b2-6c3a-4a22-a5dc-aacecf1a99dc</td>\n",
       "      <td>2949302674760005271</td>\n",
       "      <td>pdf</td>\n",
       "      <td>bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...</td>\n",
       "      <td>48981</td>\n",
       "      <td>...</td>\n",
       "      <td>5.058187</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.117808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.799880</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hap2.pdf</td>\n",
       "      <td>## HAP Example - Hate\\n\\nI hate all immigrants!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9a9c972d-86df-470b-acca-51a3135e9074</td>\n",
       "      <td>17586229987672717381</td>\n",
       "      <td>pdf</td>\n",
       "      <td>18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hap1.pdf</td>\n",
       "      <td>## HAP example - Abuse and Profanity\\n\\nYou ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>d4614cde-d599-4da9-969b-1aa9ac57310d</td>\n",
       "      <td>11080891969043035065</td>\n",
       "      <td>pdf</td>\n",
       "      <td>c21aebe6661c25c508faf03d9030813497e4ded4c840f4...</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows √ó 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename                                           contents  \\\n",
       "0  granite-similar.pdf  ## Granite Code Models: A Family of Open Found...   \n",
       "3        attention.pdf  Provided proper attribution is provided, Googl...   \n",
       "4             hap2.pdf    ## HAP Example - Hate\\n\\nI hate all immigrants!   \n",
       "5             hap1.pdf  ## HAP example - Abuse and Profanity\\n\\nYou ar...   \n",
       "\n",
       "   num_pages  num_tables  num_doc_elements  \\\n",
       "0         28          17               488   \n",
       "3         15           4               513   \n",
       "4          1           0                 3   \n",
       "5          1           0                 3   \n",
       "\n",
       "                            document_id         document_hash  ext  \\\n",
       "0  221416c6-c2a2-4aa4-be34-62b47f2b44b8   2995119145186144319  pdf   \n",
       "3  b21cf9b2-6c3a-4a22-a5dc-aacecf1a99dc   2949302674760005271  pdf   \n",
       "4  9a9c972d-86df-470b-acca-51a3135e9074  17586229987672717381  pdf   \n",
       "5  d4614cde-d599-4da9-969b-1aa9ac57310d  11080891969043035065  pdf   \n",
       "\n",
       "                                                hash    size  ...  \\\n",
       "0  0de7807974e6888cabafef3484ef571ceb5c3167f7433a...  121236  ...   \n",
       "3  bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...   48981  ...   \n",
       "4  18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...      45  ...   \n",
       "5  c21aebe6661c25c508faf03d9030813497e4ded4c840f4...     135  ...   \n",
       "\n",
       "  docq_mean_word_len  docq_symbol_to_word_ratio docq_sentence_count  \\\n",
       "0           5.177224                   0.002295                2809   \n",
       "3           5.058187                   0.004962                 541   \n",
       "4           4.000000                   0.111111                   1   \n",
       "5           4.625000                   0.041667                   2   \n",
       "\n",
       "  docq_lorem_ipsum_ratio  docq_curly_bracket_ratio  docq_contain_bad_word  \\\n",
       "0                    0.0                       0.0                  False   \n",
       "3                    0.0                       0.0                  False   \n",
       "4                    0.0                       0.0                  False   \n",
       "5                    0.0                       0.0                  False   \n",
       "\n",
       "   docq_bullet_point_ratio  docq_ellipsis_line_ratio  \\\n",
       "0                 0.110682                       0.0   \n",
       "3                 0.117808                       0.0   \n",
       "4                 0.000000                       0.0   \n",
       "5                 0.000000                       0.0   \n",
       "\n",
       "   docq_alphabet_word_ratio  docq_contain_common_en_words  \n",
       "0                  0.663245                          True  \n",
       "3                  0.799880                          True  \n",
       "4                  0.777778                         False  \n",
       "5                  0.916667                          True  \n",
       "\n",
       "[4 rows x 26 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs_df = read_parquet_files_as_df(output_doc_quality_dir)\n",
    "\n",
    "# remove documents with badwords\n",
    "clean_docs_df = all_docs_df[all_docs_df['docq_contain_bad_word'] == False]\n",
    "\n",
    "# also filter out 'lorem ipsum' text\n",
    "clean_docs_df = clean_docs_df[clean_docs_df['docq_lorem_ipsum_ratio'] == 0]\n",
    "\n",
    "clean_docs_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f003f4",
   "metadata": {},
   "source": [
    "### 7.4 -  clean quality docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6e85e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved CLEAN parquet output to 'output/6_doc_quality_clean_out'\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(output_doc_quality_clean_dir, ignore_errors=True)\n",
    "os.makedirs(output_doc_quality_clean_dir, exist_ok=True)\n",
    "\n",
    "clean_docs_df.to_parquet(os.path.join(output_doc_quality_clean_dir,\"clean_docs.parquet\"))\n",
    "print (f\"‚úÖ Saved CLEAN parquet output to '{output_doc_quality_clean_dir}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef5ed28",
   "metadata": {},
   "source": [
    "## Step-8: HAP Detector\n",
    "\n",
    "[HAP transform documentation](https://github.com/data-prep-kit/data-prep-kit/blob/dev/transforms/universal/hap/)\n",
    "\n",
    "Some parameters:\n",
    "\n",
    "- `model_name_or_path` - specify the HAP model, which should be compatible with HuggingFace's AutoModelForSequenceClassification. Defaults to IBM's open-source toxicity classifier **ibm-granite/granite-guardian-hap-38m**\n",
    "- `annotation_column` - the column name containing hap (toxicity) score in the output .parquet file. Defaults to hap_score.\n",
    "- `doc_text_column`- the column name containing the document text in the input .parquet file. Defaults to contents.\n",
    "- `batch_size` - modify it based on the infrastructure capacity. Defaults to 128.\n",
    "- `max_length` - the maximum length for the tokenizer. Defaults to 512.\n",
    "\n",
    "Here are HAP detection models\n",
    "\n",
    "- [ibm-granite/granite-guardian-hap-38m](https://huggingface.co/ibm-granite/granite-guardian-hap-38m)\n",
    "- [ibm-granite/granite-guardian-hap-125m](https://huggingface.co/ibm-granite/granite-guardian-hap-125m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb7105e",
   "metadata": {},
   "source": [
    "### 8.1 - Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c095623",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/sujee/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "{\"time\": \"22:29:55\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"hap params are {'model_name_or_path': 'ibm-granite/granite-guardian-hap-38m', 'annotation_column': 'hap_score', 'doc_text_column': 'contents', 'inference_engine': 'CPU', 'max_length': 512, 'batch_size': 128} \"}\n",
      "{\"time\": \"22:29:55\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"pipeline id pipeline_id\"}\n",
      "{\"time\": \"22:29:55\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"code location {'github': 'UNDEFINED', 'build-date': 'UNDEFINED', 'commit_hash': 'UNDEFINED', 'path': 'UNDEFINED'}\"}\n",
      "{\"time\": \"22:29:55\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ max_files -1, n_sample -1\"}\n",
      "{\"time\": \"22:29:55\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\"}\n",
      "{\"time\": \"22:29:55\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"data factory data_ Data Access:  DataAccessLocal\"}\n",
      "{\"time\": \"22:29:55\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"orchestrator hap started at 2025-11-19 22:29:55\"}\n",
      "{\"time\": \"22:29:55\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Number of files is 1, source profile {'max_file_size': 0.097381591796875, 'min_file_size': 0.097381591796875, 'total_file_size': 0.097381591796875}\"}\n",
      "{\"time\": \"22:29:56\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Processing batch: 0/7\"}\n",
      "{\"time\": \"22:30:03\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Processing batch: 1/7\"}\n",
      "{\"time\": \"22:30:11\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Processing batch: 2/7\"}\n",
      "{\"time\": \"22:30:19\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Processing batch: 3/7\"}\n",
      "{\"time\": \"22:30:26\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Processing batch: 4/7\"}\n",
      "{\"time\": \"22:30:31\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Processing batch: 5/7\"}\n",
      "{\"time\": \"22:30:37\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Processing batch: 6/7\"}\n",
      "{\"time\": \"22:30:45\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Processing batch: 7/7\"}\n",
      "{\"time\": \"22:30:45\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"              filename                                           contents  \\\\\\n0  granite-similar.pdf  ## Granite Code Models: A Family of Open Found...   \\n3        attention.pdf  Provided proper attribution is provided, Googl...   \\n4             hap2.pdf    ## HAP Example - Hate\\\\n\\\\nI hate all immigrants!   \\n5             hap1.pdf  ## HAP example - Abuse and Profanity\\\\n\\\\nYou ar...   \\n\\n   num_pages  num_tables  num_doc_elements  \\\\\\n0         28          17               488   \\n3         15           4               513   \\n4          1           0                 3   \\n5          1           0                 3   \\n\\n                            document_id         document_hash  ext  \\\\\\n0  221416c6-c2a2-4aa4-be34-62b47f2b44b8   2995119145186144319  pdf   \\n3  b21cf9b2-6c3a-4a22-a5dc-aacecf1a99dc   2949302674760005271  pdf   \\n4  9a9c972d-86df-470b-acca-51a3135e9074  17586229987672717381  pdf   \\n5  d4614cde-d599-4da9-969b-1aa9ac57310d  11080891969043035065  pdf   \\n\\n                                                hash    size  ...  \\\\\\n0  0de7807974e6888cabafef3484ef571ceb5c3167f7433a...  121236  ...   \\n3  bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...   48981  ...   \\n4  18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...      45  ...   \\n5  c21aebe6661c25c508faf03d9030813497e4ded4c840f4...     135  ...   \\n\\n  docq_symbol_to_word_ratio  docq_sentence_count docq_lorem_ipsum_ratio  \\\\\\n0                  0.002295                 2809                    0.0   \\n3                  0.004962                  541                    0.0   \\n4                  0.111111                    1                    0.0   \\n5                  0.041667                    2                    0.0   \\n\\n  docq_curly_bracket_ratio  docq_contain_bad_word  docq_bullet_point_ratio  \\\\\\n0                      0.0                  False                 0.110682   \\n3                      0.0                  False                 0.117808   \\n4                      0.0                  False                 0.000000   \\n5                      0.0                  False                 0.000000   \\n\\n   docq_ellipsis_line_ratio  docq_alphabet_word_ratio  \\\\\\n0                       0.0                  0.663245   \\n3                       0.0                  0.799880   \\n4                       0.0                  0.777778   \\n5                       0.0                  0.916667   \\n\\n   docq_contain_common_en_words  hap_score  \\n0                          True   0.154206  \\n3                          True   0.181448  \\n4                         False   0.903290  \\n5                          True   0.997993  \\n\\n[4 rows x 27 columns]\"}\n",
      "{\"time\": \"22:30:45\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed 1 files (100.0%) in 0.817 min\"}\n",
      "{\"time\": \"22:30:45\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Done processing 1 files, waiting for flush() completion.\"}\n",
      "{\"time\": \"22:30:45\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"done flushing in 0.0 sec\"}\n",
      "{\"time\": \"22:30:45\", \"logger\": \"dpk\", \"logLevel\": \"INFO\", \"message\": \"Completed execution in 0.836 min, execution result 0\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Operation completed successfully\n"
     ]
    }
   ],
   "source": [
    "from dpk_hap.transform_python import HAP\n",
    "\n",
    "\n",
    "result = HAP(input_folder= output_doc_quality_clean_dir,\n",
    "        output_folder= output_hap_detection_dir,\n",
    "        model_name_or_path= 'ibm-granite/granite-guardian-hap-38m',\n",
    "        annotation_column= \"hap_score\",\n",
    "        doc_text_column= \"contents\",\n",
    "        inference_engine= \"CPU\",\n",
    "        max_length= 512,\n",
    "        batch_size= 128,\n",
    "        ).transform()\n",
    "\n",
    "if result == 0:\n",
    "    print (f\"‚úÖ Operation completed successfully\")\n",
    "else:\n",
    "    raise Exception (f\"‚ùå Operation  failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa28b2d",
   "metadata": {},
   "source": [
    "### 8.2 - Inspect Generated output\n",
    "\n",
    "Let's see the output.  Inspect **hap_score** output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3ecee2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read 1 parquet files with 4 total rows\n",
      "Displaying contents of :  output/7_hap_detection_out\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>contents</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_hash</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>...</th>\n",
       "      <th>docq_symbol_to_word_ratio</th>\n",
       "      <th>docq_sentence_count</th>\n",
       "      <th>docq_lorem_ipsum_ratio</th>\n",
       "      <th>docq_curly_bracket_ratio</th>\n",
       "      <th>docq_contain_bad_word</th>\n",
       "      <th>docq_bullet_point_ratio</th>\n",
       "      <th>docq_ellipsis_line_ratio</th>\n",
       "      <th>docq_alphabet_word_ratio</th>\n",
       "      <th>docq_contain_common_en_words</th>\n",
       "      <th>hap_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>granite-similar.pdf</td>\n",
       "      <td>## Granite Code Models: A Family of Open Found...</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>488</td>\n",
       "      <td>221416c6-c2a2-4aa4-be34-62b47f2b44b8</td>\n",
       "      <td>2995119145186144319</td>\n",
       "      <td>pdf</td>\n",
       "      <td>0de7807974e6888cabafef3484ef571ceb5c3167f7433a...</td>\n",
       "      <td>121236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>2809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.110682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.663245</td>\n",
       "      <td>True</td>\n",
       "      <td>0.154206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention.pdf</td>\n",
       "      <td>Provided proper attribution is provided, Googl...</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>513</td>\n",
       "      <td>b21cf9b2-6c3a-4a22-a5dc-aacecf1a99dc</td>\n",
       "      <td>2949302674760005271</td>\n",
       "      <td>pdf</td>\n",
       "      <td>bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...</td>\n",
       "      <td>48981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.117808</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.799880</td>\n",
       "      <td>True</td>\n",
       "      <td>0.181448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hap2.pdf</td>\n",
       "      <td>## HAP Example - Hate\\n\\nI hate all immigrants!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9a9c972d-86df-470b-acca-51a3135e9074</td>\n",
       "      <td>17586229987672717381</td>\n",
       "      <td>pdf</td>\n",
       "      <td>18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>False</td>\n",
       "      <td>0.903290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hap1.pdf</td>\n",
       "      <td>## HAP example - Abuse and Profanity\\n\\nYou ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>d4614cde-d599-4da9-969b-1aa9ac57310d</td>\n",
       "      <td>11080891969043035065</td>\n",
       "      <td>pdf</td>\n",
       "      <td>c21aebe6661c25c508faf03d9030813497e4ded4c840f4...</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>True</td>\n",
       "      <td>0.997993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename                                           contents  \\\n",
       "0  granite-similar.pdf  ## Granite Code Models: A Family of Open Found...   \n",
       "1        attention.pdf  Provided proper attribution is provided, Googl...   \n",
       "2             hap2.pdf    ## HAP Example - Hate\\n\\nI hate all immigrants!   \n",
       "3             hap1.pdf  ## HAP example - Abuse and Profanity\\n\\nYou ar...   \n",
       "\n",
       "   num_pages  num_tables  num_doc_elements  \\\n",
       "0         28          17               488   \n",
       "1         15           4               513   \n",
       "2          1           0                 3   \n",
       "3          1           0                 3   \n",
       "\n",
       "                            document_id         document_hash  ext  \\\n",
       "0  221416c6-c2a2-4aa4-be34-62b47f2b44b8   2995119145186144319  pdf   \n",
       "1  b21cf9b2-6c3a-4a22-a5dc-aacecf1a99dc   2949302674760005271  pdf   \n",
       "2  9a9c972d-86df-470b-acca-51a3135e9074  17586229987672717381  pdf   \n",
       "3  d4614cde-d599-4da9-969b-1aa9ac57310d  11080891969043035065  pdf   \n",
       "\n",
       "                                                hash    size  ...  \\\n",
       "0  0de7807974e6888cabafef3484ef571ceb5c3167f7433a...  121236  ...   \n",
       "1  bcaa6e6e0c640fb63393c7e40229a512571f61ccdba42d...   48981  ...   \n",
       "2  18b2a552b5b54d5bd374a1416117d019a5e18a5da1547a...      45  ...   \n",
       "3  c21aebe6661c25c508faf03d9030813497e4ded4c840f4...     135  ...   \n",
       "\n",
       "  docq_symbol_to_word_ratio  docq_sentence_count docq_lorem_ipsum_ratio  \\\n",
       "0                  0.002295                 2809                    0.0   \n",
       "1                  0.004962                  541                    0.0   \n",
       "2                  0.111111                    1                    0.0   \n",
       "3                  0.041667                    2                    0.0   \n",
       "\n",
       "  docq_curly_bracket_ratio  docq_contain_bad_word  docq_bullet_point_ratio  \\\n",
       "0                      0.0                  False                 0.110682   \n",
       "1                      0.0                  False                 0.117808   \n",
       "2                      0.0                  False                 0.000000   \n",
       "3                      0.0                  False                 0.000000   \n",
       "\n",
       "   docq_ellipsis_line_ratio  docq_alphabet_word_ratio  \\\n",
       "0                       0.0                  0.663245   \n",
       "1                       0.0                  0.799880   \n",
       "2                       0.0                  0.777778   \n",
       "3                       0.0                  0.916667   \n",
       "\n",
       "   docq_contain_common_en_words  hap_score  \n",
       "0                          True   0.154206  \n",
       "1                          True   0.181448  \n",
       "2                         False   0.903290  \n",
       "3                          True   0.997993  \n",
       "\n",
       "[4 rows x 27 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from file_utils import read_parquet_files_as_df\n",
    "output_df = read_parquet_files_as_df(output_hap_detection_dir)\n",
    "print (\"Displaying contents of : \", output_hap_detection_dir)\n",
    "output_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c111b7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>contents</th>\n",
       "      <th>hap_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>granite-similar.pdf</td>\n",
       "      <td>## Granite Code Models: A Family of Open Found...</td>\n",
       "      <td>0.154206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention.pdf</td>\n",
       "      <td>Provided proper attribution is provided, Googl...</td>\n",
       "      <td>0.181448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hap2.pdf</td>\n",
       "      <td>## HAP Example - Hate\\n\\nI hate all immigrants!</td>\n",
       "      <td>0.903290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hap1.pdf</td>\n",
       "      <td>## HAP example - Abuse and Profanity\\n\\nYou ar...</td>\n",
       "      <td>0.997993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename                                           contents  \\\n",
       "0  granite-similar.pdf  ## Granite Code Models: A Family of Open Found...   \n",
       "1        attention.pdf  Provided proper attribution is provided, Googl...   \n",
       "2             hap2.pdf    ## HAP Example - Hate\\n\\nI hate all immigrants!   \n",
       "3             hap1.pdf  ## HAP example - Abuse and Profanity\\n\\nYou ar...   \n",
       "\n",
       "   hap_score  \n",
       "0   0.154206  \n",
       "1   0.181448  \n",
       "2   0.903290  \n",
       "3   0.997993  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df[['filename', 'contents', 'hap_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a23d4b4",
   "metadata": {},
   "source": [
    "### 8.3 - Extract clean docs from HAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2647b8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read 1 parquet files with 4 total rows\n",
      "clean documents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>contents</th>\n",
       "      <th>hap_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>granite-similar.pdf</td>\n",
       "      <td>## Granite Code Models: A Family of Open Found...</td>\n",
       "      <td>0.154206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attention.pdf</td>\n",
       "      <td>Provided proper attribution is provided, Googl...</td>\n",
       "      <td>0.181448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename                                           contents  \\\n",
       "0  granite-similar.pdf  ## Granite Code Models: A Family of Open Found...   \n",
       "1        attention.pdf  Provided proper attribution is provided, Googl...   \n",
       "\n",
       "   hap_score  \n",
       "0   0.154206  \n",
       "1   0.181448  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from file_utils import read_parquet_files_as_df\n",
    "\n",
    "hap_output_df = read_parquet_files_as_df(output_hap_detection_dir)\n",
    "clean_docs_df = hap_output_df[hap_output_df['hap_score'] < 0.2]\n",
    "\n",
    "print ('clean documents')\n",
    "clean_docs_df[['filename', 'contents', 'hap_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117b825b-b9cd-4608-a717-34d8abe74edd",
   "metadata": {},
   "source": [
    "## Step 9 - Save final docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c492334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## clear out final output folder\n",
    "\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(MY_CONFIG.OUTPUT_FOLDER_FINAL, ignore_errors=True)\n",
    "shutil.os.makedirs(MY_CONFIG.OUTPUT_FOLDER_FINAL, exist_ok=True)\n",
    "\n",
    "output_final_dir_parquet = os.path.join (MY_CONFIG.OUTPUT_FOLDER_FINAL, 'pq')\n",
    "shutil.os.makedirs(output_final_dir_parquet, exist_ok=True)\n",
    "\n",
    "# output_final_dir_markdown = os.path.join (MY_CONFIG.OUTPUT_FOLDER_FINAL, 'markdown')\n",
    "output_final_dir_markdown = MY_CONFIG.OUTPUT_FOLDER_FINAL_MD\n",
    "shutil.os.makedirs(output_final_dir_markdown, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a83f89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved CLEAN parquet output to 'output/output_final/pq'\n"
     ]
    }
   ],
   "source": [
    "## save parquet\n",
    "\n",
    "clean_docs_df.to_parquet(os.path.join(output_final_dir_parquet, \"clean_docs.parquet\"))\n",
    "print (f\"‚úÖ Saved CLEAN parquet output to '{output_final_dir_parquet}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58e0b857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving file: output/output_final/markdown/granite-similar.pdf.md\n",
      "Saving file: output/output_final/markdown/attention.pdf.md\n",
      "‚úÖ Saved CLEAN markdown output to 'output/output_final/markdown'\n"
     ]
    }
   ],
   "source": [
    "## save markdown text\n",
    "\n",
    "for index, row in clean_docs_df.iterrows():\n",
    "    output_file_name = os.path.join (output_final_dir_markdown, row['filename'] + '.md')\n",
    "    print (f\"Saving file: {output_file_name}\")\n",
    "    with open(output_file_name, 'w') as output_file:\n",
    "        output_file.write(row['contents'])\n",
    "\n",
    "print (f\"‚úÖ Saved CLEAN markdown output to '{output_final_dir_markdown}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpk-example-1",
   "language": "python",
   "name": "dpk-example-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
