{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG on HTML documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_config import MY_CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2: Setup Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If connection to https://huggingface.co/ failed, uncomment the following path\n",
    "import os\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f5c9957fbe4f9886c8fece1e67941e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72ff2afcb5e4679aa76a2f71b21e97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f61e38cdd5f4da6b175dc11e8b28a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ede685d9fcb4e15852c1954dce8a40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/373 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d5714a145a41afb464630c23469a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/60.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad02c73981124bd095f64811c257936c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/368 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc278bb617ff4b7289c96f31ec84f1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01104c3b068b4a12ad1a8b82f5b4a8b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de623ba76f6846829b99b533f1c2b25c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0883956662f34a9a87f7e71095ee2913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597c06e941ba42d79f2a18f551883269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling%2Fconfig.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name = MY_CONFIG.EMBEDDING_MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3: Connect to Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 12:11:37,375 [DEBUG][_create_connection]: Created new connection using: 13c2c064b8414803a37944ff446dd487 (async_milvus_client.py:600)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to Milvus instance:  ./rag_website.db\n"
     ]
    }
   ],
   "source": [
    "# connect to vector db\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "\n",
    "vector_store = MilvusVectorStore(\n",
    "    uri = MY_CONFIG.DB_URI ,\n",
    "    dim = MY_CONFIG.EMBEDDING_LENGTH , \n",
    "    collection_name = MY_CONFIG.COLLECTION_NAME,\n",
    "    overwrite=False  # so we load the index from db\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "print (\"✅ Connected to Milvus instance: \", MY_CONFIG.DB_URI )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-4: Load Document Index from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded index from vector db: ./rag_website.db\n",
      "CPU times: user 96.8 ms, sys: 17 ms, total: 114 ms\n",
      "Wall time: 121 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, storage_context=storage_context)\n",
    "\n",
    "print (\"✅ Loaded index from vector db:\", MY_CONFIG.DB_URI )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-5: Setup LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.replicate import Replicate\n",
    "from llama_index.core import Settings\n",
    "\n",
    "llm = Replicate(\n",
    "    model= MY_CONFIG.LLM_MODEL,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-6: Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AI Alliance is an international community of developers, researchers, and organizations dedicated to promoting open, safe, and responsible artificial intelligence. It was launched in December 2023 and emphasizes the importance of open technologies, encouraging their adoption across various sectors to foster an environment where AI can thrive and benefit people and society worldwide. The Alliance aims to accelerate and disseminate open innovation across the AI technology landscape, focusing on improving foundational capabilities, safety, security, and trust in AI while responsibly maximizing its benefits. It does this through a broad, heterogeneous program that embraces diversity of thought and action, with a lightweight operating and governing structure that empowers individual collaborators and organizational members and sponsors. The AI Alliance has established its first two member-driven working groups, AI Safety and Trust Tooling, and AI Policy Advocacy, to address challenges related to generative AI and democratize its benefits.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "res = query_engine.query(\"What is AI Alliance?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AI Alliance has six goal-oriented thematic programs, known as Focus Areas. These are:\n",
      "\n",
      "1. Foundational Capabilities\n",
      "2. Safety, Security, and Trust\n",
      "3. Responsible AI Development\n",
      "4. Open Foundation Models\n",
      "5. AI Hardware Accelerators\n",
      "6. Global AI Skills Building and Education\n",
      "\n",
      "These Focus Areas guide the AI Alliance's efforts in advancing the responsible development and use of AI systems at a global scale.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "res = query_engine.query(\"What are the main focus areas of AI Alliance?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, the AI Alliance members plan to start or enhance projects with the following objectives:\n",
      "\n",
      "1. Deploying benchmarks, tools, and resources for responsible AI development and use at a global scale, including a catalog of vetted safety, security, and trust tools.\n",
      "2. Advancing the ecosystem of open foundation models with diverse modalities, such as multilingual, multi-modal, and science models, to address societal challenges.\n",
      "3. Fostering a vibrant AI hardware accelerator ecosystem by boosting contributions and adoption of essential enabling software technology.\n",
      "4. Supporting global AI skills building, education, and exploratory research, engaging the academic community to support AI model and tool research projects.\n",
      "5. Developing educational content and resources to inform the public and policymakers about AI's benefits, risks, solutions, and precision regulation.\n",
      "6. Launching initiatives that encourage open development of AI in safe and beneficial ways, and hosting events to explore AI use cases and showcase responsible AI applications.\n",
      "\n",
      "These projects are categorized as Core Projects, which are managed directly by the AI Alliance and governed according to the defined governance structure. Affiliated Projects, while not managed directly by the AI Alliance, are typically from member organizations seeking deeper collaboration and impact, often building upon or with Core Projects or other Affiliated Projects.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "res = query_engine.query(\"What are some ai alliance projects?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The demo night was held in San Francisco, California.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "res = query_engine.query(\"Where was the demo night held?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry for any confusion, but the provided context information does not contain details about the moon landing. The context discusses two AI-related projects: LLM360 and Lightning AI's open-source frameworks for GenAI builders. The first project involves releasing various components of a 7B English language model, while the second project focuses on maintaining and expanding open-source frameworks like PyTorch Lightning and TorchMetrics. The moon landing occurred on July 20, 1969, as part of the Apollo 11 mission.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "res = query_engine.query(\"When was the moon landing?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AI Alliance is focusing on materials science through the Materials and Chemistry Working Group. They curate datasets, tasks, and benchmarks for materials science, build foundation models in chemistry for predicting properties, experimental outcomes, or generating new candidates. Their current open-source models include SMILES-TED, SMI-SSED, SELFIES-TED, and MHG-GED, which are pre-trained on curated datasets from PubChem and support various complex tasks in quantum property prediction.\n",
      "\n",
      "Additionally, the AI Alliance is working on several projects related to materials science, such as:\n",
      "\n",
      "1. Training fused foundation models.\n",
      "2. Trans-dimensional flow-matching for molecular generation.\n",
      "3. Training of GFlowNets for materials generation.\n",
      "4. Reproducing AlphaFold 3 capabilities.\n",
      "5. Organizing hackathons.\n",
      "\n",
      "Their ultimate goal is to create a framework that fosters collaboration between human experts and AI agents to address global urgent challenges in sustainability and safety of materials.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "res = query_engine.query(\"What is the AI Alliance doing in the area of material science?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To join the AI Alliance, you can follow these steps:\n",
      "\n",
      "1. As an organization: Send a message via the AI Alliance contact form available at [https://thealliance.ai/contact](https://thealliance.ai/contact).\n",
      "\n",
      "2. As an individual contributor: Complete the working group application form available at [https://thealliance.ai/become-a-collaborator](https://thealliance.ai/become-a-collaborator).\n",
      "\n",
      "Once your application is reviewed and approved, you will be invited to the AI Alliance Slack and receive additional instructions on how to join the community.\n",
      "\n",
      "For more information or to ask additional questions, you can contact the AI Alliance at [https://thealliance.ai/contact](https://thealliance.ai/contact).\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "res = query_engine.query(\"How do I join the AI Alliance?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-website-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
