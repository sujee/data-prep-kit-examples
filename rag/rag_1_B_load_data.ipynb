{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Processed Data into Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConfig:\n",
    "    pass\n",
    "MY_CONFIG = MyConfig()\n",
    "\n",
    "MY_CONFIG.INPUT_DATA_DIR = 'data/granite-docs/output_final/'\n",
    "# MY_CONFIG.INPUT_DATA_REMOTE = \"https://github.com/sujee/data-prep-kit-examples/blob/main/requirements.txt\"\n",
    "MY_CONFIG.DB_NAME = \"rag_demo.db\"  # vector db (embedded)\n",
    "MY_CONFIG.COLLECTION_NAME = \"docs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure out Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT running in Colab\n"
     ]
    }
   ],
   "source": [
    "# are we running in Colab?\n",
    "import os\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "   print(\"Running in Colab\")\n",
    "   MY_CONFIG.RUNNING_IN_COLAB = True\n",
    "else:\n",
    "   print(\"NOT running in Colab\")\n",
    "   MY_CONFIG.RUNNING_IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies (If required)\n",
    "\n",
    "**A note for Google Colab Users**\n",
    "\n",
    "After installing the dependenceis, if you get errors loading libraries, **restart runtime** and **run the notebook** again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MY_CONFIG.RUNNING_IN_COLAB:\n",
    "  !pip install pymilvus  'pymilvus[model]'  datasets  sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-: Load Parquet Data\n",
    "\n",
    "Load all  `.parquet` files in the given dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from :  data/granite-docs/output_final/\n",
      "Number of parquet files to read :  1\n",
      "\n",
      "Read file: 'data/granite-docs/output_final/Granite_Foundation_Models.parquet'.  number of rows = 235\n",
      "\n",
      "Total number of rows = 235\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "print ('Loading data from : ', MY_CONFIG.INPUT_DATA_DIR)\n",
    "\n",
    "# Get a list of all Parquet files in the directory\n",
    "parquet_files = glob.glob(f'{MY_CONFIG.INPUT_DATA_DIR}/*.parquet')\n",
    "print (\"Number of parquet files to read : \", len(parquet_files))\n",
    "print ()\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each Parquet file and read it into a DataFrame\n",
    "for file in parquet_files:\n",
    "    df = pd.read_parquet(file)\n",
    "    print (f\"Read file: '{file}'.  number of rows = {df.shape[0]}\")\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "data_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print (f\"\\nTotal number of rows = {data_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding length:  384\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 235 entries, 0 to 234\n",
      "Data columns (total 29 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   filename                      235 non-null    object \n",
      " 1   num_pages                     235 non-null    int64  \n",
      " 2   num_tables                    235 non-null    int64  \n",
      " 3   num_doc_elements              235 non-null    int64  \n",
      " 4   document_id                   235 non-null    object \n",
      " 5   ext                           235 non-null    object \n",
      " 6   hash                          235 non-null    object \n",
      " 7   size                          235 non-null    int64  \n",
      " 8   date_acquired                 235 non-null    object \n",
      " 9   pdf_convert_time              235 non-null    float64\n",
      " 10  source_filename               235 non-null    object \n",
      " 11  contents                      235 non-null    object \n",
      " 12  doc_path                      235 non-null    object \n",
      " 13  int_id_column                 235 non-null    int64  \n",
      " 14  hash_column                   235 non-null    int64  \n",
      " 15  ft_lang                       235 non-null    object \n",
      " 16  ft_score                      235 non-null    float64\n",
      " 17  docq_total_words              235 non-null    int64  \n",
      " 18  docq_mean_word_len            235 non-null    float64\n",
      " 19  docq_symbol_to_word_ratio     235 non-null    float64\n",
      " 20  docq_sentence_count           235 non-null    int64  \n",
      " 21  docq_lorem_ipsum_ratio        235 non-null    float64\n",
      " 22  docq_curly_bracket_ratio      235 non-null    float64\n",
      " 23  docq_contain_bad_word         235 non-null    bool   \n",
      " 24  docq_bullet_point_ratio       235 non-null    float64\n",
      " 25  docq_ellipsis_line_ratio      235 non-null    float64\n",
      " 26  docq_alphabet_word_ratio      235 non-null    float64\n",
      " 27  docq_contain_common_en_words  235 non-null    bool   \n",
      " 28  vector                        235 non-null    object \n",
      "dtypes: bool(2), float64(9), int64(8), object(10)\n",
      "memory usage: 50.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>num_tables</th>\n",
       "      <th>num_doc_elements</th>\n",
       "      <th>document_id</th>\n",
       "      <th>ext</th>\n",
       "      <th>hash</th>\n",
       "      <th>size</th>\n",
       "      <th>date_acquired</th>\n",
       "      <th>pdf_convert_time</th>\n",
       "      <th>...</th>\n",
       "      <th>docq_symbol_to_word_ratio</th>\n",
       "      <th>docq_sentence_count</th>\n",
       "      <th>docq_lorem_ipsum_ratio</th>\n",
       "      <th>docq_curly_bracket_ratio</th>\n",
       "      <th>docq_contain_bad_word</th>\n",
       "      <th>docq_bullet_point_ratio</th>\n",
       "      <th>docq_ellipsis_line_ratio</th>\n",
       "      <th>docq_alphabet_word_ratio</th>\n",
       "      <th>docq_contain_common_en_words</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Granite%20Foundation%20Models.pdf</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>445</td>\n",
       "      <td>d141f01c-c838-49b0-a8f2-0c80b3761d88</td>\n",
       "      <td>pdf</td>\n",
       "      <td>cfce6b11703e9b81d1958b54b135bc4a5c5d8771032e6b...</td>\n",
       "      <td>455938</td>\n",
       "      <td>2024-07-29T22:05:04.500431</td>\n",
       "      <td>37.934728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.007855909, 0.018679393, 0.042436924, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Granite%20Foundation%20Models.pdf</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>445</td>\n",
       "      <td>d141f01c-c838-49b0-a8f2-0c80b3761d88</td>\n",
       "      <td>pdf</td>\n",
       "      <td>cfce6b11703e9b81d1958b54b135bc4a5c5d8771032e6b...</td>\n",
       "      <td>455938</td>\n",
       "      <td>2024-07-29T22:05:04.500431</td>\n",
       "      <td>37.934728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[-0.0035767434, 0.009818679, 0.03441954, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Granite%20Foundation%20Models.pdf</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>445</td>\n",
       "      <td>d141f01c-c838-49b0-a8f2-0c80b3761d88</td>\n",
       "      <td>pdf</td>\n",
       "      <td>cfce6b11703e9b81d1958b54b135bc4a5c5d8771032e6b...</td>\n",
       "      <td>455938</td>\n",
       "      <td>2024-07-29T22:05:04.500431</td>\n",
       "      <td>37.934728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>[-0.022207903, 0.0050711804, 0.022928528, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            filename  num_pages  num_tables  num_doc_elements  \\\n",
       "0  Granite%20Foundation%20Models.pdf         20          13               445   \n",
       "1  Granite%20Foundation%20Models.pdf         20          13               445   \n",
       "2  Granite%20Foundation%20Models.pdf         20          13               445   \n",
       "\n",
       "                            document_id  ext  \\\n",
       "0  d141f01c-c838-49b0-a8f2-0c80b3761d88  pdf   \n",
       "1  d141f01c-c838-49b0-a8f2-0c80b3761d88  pdf   \n",
       "2  d141f01c-c838-49b0-a8f2-0c80b3761d88  pdf   \n",
       "\n",
       "                                                hash    size  \\\n",
       "0  cfce6b11703e9b81d1958b54b135bc4a5c5d8771032e6b...  455938   \n",
       "1  cfce6b11703e9b81d1958b54b135bc4a5c5d8771032e6b...  455938   \n",
       "2  cfce6b11703e9b81d1958b54b135bc4a5c5d8771032e6b...  455938   \n",
       "\n",
       "                date_acquired  pdf_convert_time  ...  \\\n",
       "0  2024-07-29T22:05:04.500431         37.934728  ...   \n",
       "1  2024-07-29T22:05:04.500431         37.934728  ...   \n",
       "2  2024-07-29T22:05:04.500431         37.934728  ...   \n",
       "\n",
       "  docq_symbol_to_word_ratio docq_sentence_count docq_lorem_ipsum_ratio  \\\n",
       "0                       0.0                   2                    0.0   \n",
       "1                       0.0                   1                    0.0   \n",
       "2                       0.0                   6                    0.0   \n",
       "\n",
       "   docq_curly_bracket_ratio  docq_contain_bad_word docq_bullet_point_ratio  \\\n",
       "0                       0.0                  False                     0.0   \n",
       "1                       0.0                  False                     0.0   \n",
       "2                       0.0                  False                     0.0   \n",
       "\n",
       "   docq_ellipsis_line_ratio  docq_alphabet_word_ratio  \\\n",
       "0                       0.0                       1.0   \n",
       "1                       0.0                       1.0   \n",
       "2                       0.0                       1.0   \n",
       "\n",
       "   docq_contain_common_en_words  \\\n",
       "0                          True   \n",
       "1                         False   \n",
       "2                          True   \n",
       "\n",
       "                                              vector  \n",
       "0  [-0.007855909, 0.018679393, 0.042436924, -0.01...  \n",
       "1  [-0.0035767434, 0.009818679, 0.03441954, -0.00...  \n",
       "2  [-0.022207903, 0.0050711804, 0.022928528, -0.0...  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## Shape the data\n",
    "\n",
    "MY_CONFIG.EMBEDDING_LENGTH =  len(data_df.iloc[0]['embeddings'])\n",
    "print ('embedding length: ', MY_CONFIG.EMBEDDING_LENGTH)\n",
    "\n",
    "# rename 'embeddings' columns as 'vector' to match default schema\n",
    "if 'vector' not in data_df.columns and 'embeddings' in data_df.columns:\n",
    "    data_df = data_df.rename( columns= {'embeddings' : 'vector'})\n",
    "\n",
    "print (data_df.info())\n",
    "data_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Vector Database\n",
    "\n",
    "Milvus can be embedded and easy to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "client = MilvusClient(MY_CONFIG.DB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create A Collection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized vector db: rag_demo.db , collection:  docs\n"
     ]
    }
   ],
   "source": [
    "# if we already have a collection, clear it first\n",
    "if client.has_collection(collection_name=MY_CONFIG.COLLECTION_NAME):\n",
    "    client.drop_collection(collection_name=MY_CONFIG.COLLECTION_NAME)\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=MY_CONFIG.COLLECTION_NAME,\n",
    "    dimension=MY_CONFIG.EMBEDDING_LENGTH,\n",
    "    auto_id=True\n",
    ")\n",
    "print (\"Initialized vector db:\", MY_CONFIG.DB_NAME, \", collection: \", MY_CONFIG.COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df.to_dict('records')[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted # rows 235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'row_count': 235}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = client.insert(collection_name=MY_CONFIG.COLLECTION_NAME, data=data_df.to_dict('records'))\n",
    "\n",
    "print('inserted # rows', res['insert_count'])\n",
    "\n",
    "client.get_collection_stats(MY_CONFIG.COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do A Simple Vector Search\n",
    "\n",
    "We will do this to verify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sujee/apps/anaconda3/envs/data-prep-kit-1/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import model\n",
    "import random\n",
    "\n",
    "# If connection to https://huggingface.co/ failed, uncomment the following path\n",
    "# import os\n",
    "# os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "# embedding_fn = model.DefaultEmbeddingFunction()\n",
    "\n",
    "## initialize the SentenceTransformerEmbeddingFunction\n",
    "embedding_fn = model.dense.SentenceTransformerEmbeddingFunction(\n",
    "    model_name='BAAI/bge-small-en-v1.5',\n",
    "    device='cpu' # this will work on all devices (KIS)\n",
    ")\n",
    "\n",
    "## helper function to perform vector search\n",
    "def  do_vector_search (query):\n",
    "    # query_vectors = embedding_fn.encode_queries([query])\n",
    "    query_vectors = embedding_fn([query])\n",
    "\n",
    "    results = client.search(\n",
    "        collection_name=MY_CONFIG.COLLECTION_NAME,  # target collection\n",
    "        data=query_vectors,  # query vectors\n",
    "        limit=5,  # number of returned entities\n",
    "        output_fields=[\"filename\", \"page_number\", \"text\"],  # specifies fields to be returned\n",
    "    )\n",
    "    return results\n",
    "## ----\n",
    "\n",
    "def  print_search_results (results):\n",
    "    # pprint (results)\n",
    "    print ('num results : ', len(results[0]))\n",
    "\n",
    "    for i, r in enumerate (results[0]):\n",
    "        #pprint(r, indent=4)\n",
    "        print (i+1)\n",
    "        print ('search score:', r['distance'])\n",
    "        print ('filename:', r['entity']['filename'])\n",
    "        # print ('text:', r['entity']['text'])\n",
    "        ## TODO : print text and page number\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num results :  5\n",
      "1\n",
      "search score: 0.8775781393051147\n",
      "filename: Granite%20Foundation%20Models.pdf\n",
      "\n",
      "2\n",
      "search score: 0.8280448913574219\n",
      "filename: Granite%20Foundation%20Models.pdf\n",
      "\n",
      "3\n",
      "search score: 0.8216304779052734\n",
      "filename: Granite%20Foundation%20Models.pdf\n",
      "\n",
      "4\n",
      "search score: 0.8174999952316284\n",
      "filename: Granite%20Foundation%20Models.pdf\n",
      "\n",
      "5\n",
      "search score: 0.8016889691352844\n",
      "filename: Granite%20Foundation%20Models.pdf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Overview of the Granite Pre-Training Dataset\"\n",
    "\n",
    "results = do_vector_search (query)\n",
    "print_search_results(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-prep-kit-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
